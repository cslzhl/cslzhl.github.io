<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>cs-cloud GPU服务器环境配置</title>
    <url>/archives/175f7e9.html</url>
    <content><![CDATA[<h1 id="配置Docker源"><a href="#配置Docker源" class="headerlink" title="配置Docker源"></a>配置Docker源</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 更新源</span><br><span class="line">$ sudo apt update</span><br><span class="line"></span><br><span class="line"># 启用HTTPS</span><br><span class="line">$ sudo apt install -y \</span><br><span class="line">    apt-transport-https \</span><br><span class="line">    ca-certificates \</span><br><span class="line">    curl \</span><br><span class="line">    gnupg-agent \</span><br><span class="line">    software-properties-common</span><br><span class="line"></span><br><span class="line"># 添加GPG key</span><br><span class="line">$ curl -fsSL https:&#x2F;&#x2F;download.docker.com&#x2F;linux&#x2F;ubuntu&#x2F;gpg | sudo apt-key add -</span><br><span class="line"></span><br><span class="line"># 添加稳定版的源</span><br><span class="line">$ sudo add-apt-repository \</span><br><span class="line">   &quot;deb [arch&#x3D;amd64] https:&#x2F;&#x2F;download.docker.com&#x2F;linux&#x2F;ubuntu \</span><br><span class="line">   $(lsb_release -cs) \</span><br><span class="line">   stable&quot;</span><br></pre></td></tr></table></figure>
<h1 id="安装Docker-CE"><a href="#安装Docker-CE" class="headerlink" title="安装Docker CE"></a>安装Docker CE</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 更新源</span><br><span class="line">$ sudo apt update</span><br><span class="line"></span><br><span class="line"># 安装Docker CE</span><br><span class="line">$ sudo apt install -y docker-ce</span><br></pre></td></tr></table></figure>
<h1 id="验证Docker-CE"><a href="#验证Docker-CE" class="headerlink" title="验证Docker CE"></a>验证Docker CE</h1><p>如果出现下面的内容，说明安装成功。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ sudo docker run hello-world</span><br><span class="line"></span><br><span class="line">Unable to find image &#39;hello-world:latest&#39; locally</span><br><span class="line">latest: Pulling from library&#x2F;hello-world</span><br><span class="line">1b930d010525: Pull complete </span><br><span class="line">Digest: sha256:2557e3c07ed1e38f26e389462d03ed943586f744621577a99efb77324b0fe535</span><br><span class="line">Status: Downloaded newer image for hello-world:latest</span><br><span class="line"></span><br><span class="line">Hello from Docker!</span><br><span class="line">This message shows that your installation appears to be working correctly.</span><br><span class="line"></span><br><span class="line">To generate this message, Docker took the following steps:</span><br><span class="line"> 1. The Docker client contacted the Docker daemon.</span><br><span class="line"> 2. The Docker daemon pulled the &quot;hello-world&quot; image from the Docker Hub.</span><br><span class="line">    (amd64)</span><br><span class="line"> 3. The Docker daemon created a new container from that image which runs the</span><br><span class="line">    executable that produces the output you are currently reading.</span><br><span class="line"> 4. The Docker daemon streamed that output to the Docker client, which sent it</span><br><span class="line">    to your terminal.</span><br><span class="line"></span><br><span class="line">To try something more ambitious, you can run an Ubuntu container with:</span><br><span class="line"> $ docker run -it ubuntu bash</span><br><span class="line"></span><br><span class="line">Share images, automate workflows, and more with a free Docker ID:</span><br><span class="line"> https:&#x2F;&#x2F;hub.docker.com&#x2F;</span><br><span class="line"></span><br><span class="line">For more examples and ideas, visit:</span><br><span class="line"> https:&#x2F;&#x2F;docs.docker.com&#x2F;get-started&#x2F;</span><br></pre></td></tr></table></figure>
<h1 id="配置nvidia-docker源"><a href="#配置nvidia-docker源" class="headerlink" title="配置nvidia-docker源"></a>配置nvidia-docker源</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 添加源</span><br><span class="line">$ distribution&#x3D;$(. &#x2F;etc&#x2F;os-release;echo $ID$VERSION_ID)</span><br><span class="line">$ curl -s -L https:&#x2F;&#x2F;nvidia.github.io&#x2F;nvidia-docker&#x2F;gpgkey | sudo apt-key add -</span><br><span class="line">$ curl -s -L https:&#x2F;&#x2F;nvidia.github.io&#x2F;nvidia-docker&#x2F;$distribution&#x2F;nvidia-docker.list | sudo tee &#x2F;etc&#x2F;apt&#x2F;sources.list.d&#x2F;nvidia-docker.list</span><br><span class="line"></span><br><span class="line"># 安装并重启docker</span><br><span class="line">$ sudo apt update &amp;&amp; sudo apt install -y nvidia-container-toolkit</span><br><span class="line">$ sudo systemctl restart docker</span><br></pre></td></tr></table></figure>
<h1 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 在官方CUDA镜像上测试 nvidia-smi</span><br><span class="line">$ sudo docker run --gpus all nvidia&#x2F;cuda:9.0-base nvidia-smi</span><br><span class="line"></span><br><span class="line"># 启动支持双GPU的容器</span><br><span class="line">$ sudo docker run --gpus 2 nvidia&#x2F;cuda:9.0-base nvidia-smi</span><br><span class="line"></span><br><span class="line"># 指定GPU 1，运行容器</span><br><span class="line">$ sudo docker run --gpus device&#x3D;0 nvidia&#x2F;cuda:9.0-base nvidia-smi</span><br></pre></td></tr></table></figure>
<p>能看到显卡信息就说明OK了，当前image是基于Ubuntu 16.04的。</p>
<h1 id="docker-默认存储目录更改"><a href="#docker-默认存储目录更改" class="headerlink" title="docker 默认存储目录更改"></a>docker 默认存储目录更改</h1><p>查看Docker默认存储目录：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 查看docker基本信息</span><br><span class="line">$ docker info</span><br><span class="line">...</span><br><span class="line">Docker Root Dir: &#x2F;var&#x2F;lib&#x2F;docker</span><br><span class="line">Debug Mode: false</span><br><span class="line">Registry: https:&#x2F;&#x2F;index.docker.io&#x2F;v1&#x2F;</span><br><span class="line">Labels:</span><br><span class="line">Experimental: false</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ sudo systemctl stop docker</span><br><span class="line">$ sudo vim &#x2F;etc&#x2F;docker&#x2F;daemon.json</span><br><span class="line">&#123;</span><br><span class="line">  &quot;registry-mirrors&quot;: [&quot;http:&#x2F;&#x2F;hub-mirror.c.163.com&quot;],</span><br><span class="line">  &quot;data-root&quot;: &quot;&#x2F;mnt&#x2F;data&quot; &#x2F;&#x2F;添加存储路径</span><br><span class="line">&#125;</span><br><span class="line">$ sudo systemctl start docker</span><br></pre></td></tr></table></figure>
<h1 id="删除镜像和容器"><a href="#删除镜像和容器" class="headerlink" title="删除镜像和容器"></a>删除镜像和容器</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo docker images # 查看所有镜像</span><br><span class="line">sudo docker ps -a # 显示所有容器</span><br><span class="line">sudo docker rm 容器id # 删除容器</span><br><span class="line">sudo docker rmi 镜像id # 删除镜像</span><br></pre></td></tr></table></figure>

<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol>
<li><a href="https://www.cnblogs.com/journeyonmyway/p/11234572.html">Ubuntu 18.04安装Docker CE及NVIDIA Container Toolkit流程</a></li>
</ol>
]]></content>
      <categories>
        <category>ubuntu</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title>hexo主题美化及常用插件使用</title>
    <url>/archives/a6fdd32d.html</url>
    <content><![CDATA[<p>前言：本博客搭建时使用的nodejs版本为12.20.1，hexo版本为5.3.0，next版本为7.4.0，初次搭建推荐做一些文件改动时就测试一下(我到最后才发现hexo d居然出问题，艹)</p>
<a id="more"></a>

<h1 id="站点配置"><a href="#站点配置" class="headerlink" title="站点配置"></a>站点配置</h1><h2 id="修改post初始生成样式"><a href="#修改post初始生成样式" class="headerlink" title="修改post初始生成样式"></a>修改post初始生成样式</h2><p>在目录scaffolds下，修改post.md</p>
<h1 id="主题配置"><a href="#主题配置" class="headerlink" title="主题配置"></a>主题配置</h1><h2 id="fork-me-on-github"><a href="#fork-me-on-github" class="headerlink" title="fork me on github"></a>fork me on github</h2><p>当前版本next集成了这个功能。在<strong>主题配置</strong>中修改即可</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># &#96;Follow me on GitHub&#96; banner in the top-right corner.</span><br><span class="line">github_banner:</span><br><span class="line">  enable: true</span><br><span class="line">  permalink: https:&#x2F;&#x2F;github.com&#x2F;cslzhl</span><br><span class="line">  title: Follow me on GitHub</span><br></pre></td></tr></table></figure>
<hr>
<p>之前版本在<strong>主题目录</strong>(themes/next/layout)下修改_layout.swig文件，可从<a href="https://tholman.com/github-corners/">GitHub Corners</a>中选一种样式</p>
<figure class="highlight diff"><table><tr><td class="code"><pre><span class="line">&lt;div class=&quot;&#123;&#123; container_class &#125;&#125; &#123;% block page_class %&#125;&#123;% endblock %&#125; &quot;&gt;</span><br><span class="line">&lt;div class=&quot;headband&quot;&gt;&lt;/div&gt;</span><br><span class="line"><span class="addition">+ &lt;a href=&quot;https://github.com/cslzhl&quot; class=&quot;github-corner&quot; aria-label=&quot;View source on GitHub&quot;&gt;&lt;svg width=&quot;80&quot; height=&quot;80&quot; viewBox=&quot;0 0 250 250&quot; style=&quot;fill:#64CEAA; color:#fff; position: absolute; top: 0; border: 0; right: 0;&quot; aria-hidden=&quot;true&quot;&gt;&lt;path d=&quot;M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2&quot; fill=&quot;currentColor&quot; style=&quot;transform-origin: 130px 106px;&quot; class=&quot;octo-arm&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z&quot; fill=&quot;currentColor&quot; class=&quot;octo-body&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;style&gt;.github-corner:hover .octo-arm&#123;animation:octocat-wave 560ms ease-in-out&#125;@keyframes octocat-wave&#123;0%,100%&#123;transform:rotate(0)&#125;20%,60%&#123;transform:rotate(-25deg)&#125;40%,80%&#123;transform:rotate(10deg)&#125;&#125;@media (max-width:500px)&#123;.github-corner:hover .octo-arm&#123;animation:none&#125;.github-corner .octo-arm&#123;animation:octocat-wave 560ms ease-in-out&#125;&#125;&lt;/style&gt;</span></span><br></pre></td></tr></table></figure>
<h2 id="阅读全文跳转"><a href="#阅读全文跳转" class="headerlink" title="阅读全文跳转"></a>阅读全文跳转</h2><p>修改主题文件(themes/next/layout/_macro/post.swig)</p>
<figure class="highlight diff"><table><tr><td class="code"><pre><span class="line"><span class="deletion">- &lt;a class=&quot;btn&quot; href=&quot;&#123;&#123; url_for(post.path) &#125;&#125;#more&quot; rel=&quot;contents&quot;&gt;</span></span><br><span class="line"><span class="addition">+ &lt;a class=&quot;btn&quot; href=&quot;&#123;&#123; url_for(post.path) &#125;&#125;&quot; rel=&quot;contents&quot;&gt;</span></span><br></pre></td></tr></table></figure>
<hr>
<p><strong>以下方法以失效</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">scroll_to_more: false</span><br></pre></td></tr></table></figure>
<h2 id="推荐文章插件"><a href="#推荐文章插件" class="headerlink" title="推荐文章插件"></a>推荐文章插件</h2><p>这个帮助我们根据标签推荐相关文章，当前版本NexT主题集成了这个插件的配置。</p>
<h3 id="地址"><a href="#地址" class="headerlink" title="地址"></a>地址</h3><p><a href="https://github.com/tea3/hexo-related-popular-posts">hexo-related-popular-posts</a></p>
<h3 id="安装配置"><a href="#安装配置" class="headerlink" title="安装配置"></a>安装配置</h3><p>安装插件</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">npm install hexo-related-popular-posts --save</span><br></pre></td></tr></table></figure>
<p>修改主题配置</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">related_posts:</span><br><span class="line">  enable: true</span><br><span class="line">  title: 推荐文章 # Custom header, leave empty to use the default one</span><br><span class="line">  display_in_home: false</span><br><span class="line">  params:</span><br><span class="line">    maxCount: 5</span><br><span class="line">    PPMixingRate: 0.25</span><br><span class="line">    isDate: false</span><br><span class="line">    isImage: false</span><br><span class="line">    isExcerpt: false</span><br></pre></td></tr></table></figure>
<h2 id="Hexo修改back2top标签"><a href="#Hexo修改back2top标签" class="headerlink" title="Hexo修改back2top标签"></a>Hexo修改back2top标签</h2><h3 id="地址-1"><a href="#地址-1" class="headerlink" title="地址"></a>地址</h3><p><a href="https://github.com/jiangtj-lab/hexo-cake-moon-menu">hexo-cake-moon-menu</a></p>
<h3 id="安装配置-1"><a href="#安装配置-1" class="headerlink" title="安装配置"></a>安装配置</h3><p>安装插件</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">npm install hexo-cake-moon-menu --save</span><br></pre></td></tr></table></figure>
<p>修改站点配置<br>在站点配置文件_config.yml 中添加以下代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">moon_menu:</span><br><span class="line">  back2top:</span><br><span class="line">    enable: true</span><br><span class="line">    icon: fa fa-chevron-up</span><br><span class="line">    func: back2top</span><br><span class="line">    order: -1</span><br><span class="line">  back2bottom:</span><br><span class="line">    enable: true</span><br><span class="line">    icon: fa fa-chevron-down</span><br><span class="line">    func: back2bottom</span><br><span class="line">    order: -2</span><br></pre></td></tr></table></figure>
<hr>
<p>在next主题配置中，以下为back2top条：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">back2top:</span><br><span class="line">  enable: true</span><br><span class="line">  # Back to top in sidebar.</span><br><span class="line">  sidebar: true # 在左边文章目录下</span><br><span class="line">  # Scroll percent label in b2t button.</span><br><span class="line">  scrollpercent: true # 显示百分比</span><br></pre></td></tr></table></figure>
<h2 id="侧边栏标签等数字显示"><a href="#侧边栏标签等数字显示" class="headerlink" title="侧边栏标签等数字显示"></a>侧边栏标签等数字显示</h2><p>修改next主题配置</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">menu_settings:</span><br><span class="line">  icons: true</span><br><span class="line">  badges: true</span><br></pre></td></tr></table></figure>
<h2 id="Hexo文章加密插件"><a href="#Hexo文章加密插件" class="headerlink" title="Hexo文章加密插件"></a>Hexo文章加密插件</h2><h3 id="地址-2"><a href="#地址-2" class="headerlink" title="地址"></a>地址</h3><p><a href="https://github.com/D0n9X1n/hexo-blog-encrypt">hexo-blog-encrypt</a></p>
<h3 id="安装配置-2"><a href="#安装配置-2" class="headerlink" title="安装配置"></a>安装配置</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">npm install hexo-blog-encrypt --save</span><br></pre></td></tr></table></figure>
<p>修改站点配置文件,增加如下代码</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Security</span><br><span class="line">encrypt: # hexo-blog-encrypt</span><br><span class="line">  abstract: 有东西被加密了, 请输入密码查看.</span><br><span class="line">  message: 您好, 这里需要密码.</span><br><span class="line">  tags:</span><br><span class="line">  - &#123;name: tagName, password: 密码A&#125;</span><br><span class="line">  - &#123;name: tagName, password: 密码B&#125;</span><br><span class="line">  wrong_pass_message: 抱歉, 这个密码看着不太对, 请再试试.</span><br><span class="line">  wrong_hash_message: 抱歉, 这个文章不能被校验, 不过您还是能看看解密后的内容.</span><br></pre></td></tr></table></figure>
<p>对博文禁用 Tag 加密</p>
<p>只需要将博文头部的 password 设置为 “” 即可取消 Tag 加密.</p>
<h2 id="Hexo-豆瓣读书、豆瓣电影插件"><a href="#Hexo-豆瓣读书、豆瓣电影插件" class="headerlink" title="Hexo 豆瓣读书、豆瓣电影插件"></a>Hexo 豆瓣读书、豆瓣电影插件</h2><h3 id="安装配置-3"><a href="#安装配置-3" class="headerlink" title="安装配置"></a>安装配置</h3><p>安装插件：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">npm install hexo-douban --save</span><br></pre></td></tr></table></figure>
<p>启动：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo clean &amp;&amp; hexo douban -bgm &amp;&amp; hexo g &amp;&amp; hexo s</span><br></pre></td></tr></table></figure>
<h3 id=""><a href="#" class="headerlink" title=""></a></h3><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol>
<li><a href="https://tding.top/archives/567debe0.html">本博客当前使用的插件总结</a></li>
</ol>
]]></content>
      <categories>
        <category>建站教程</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>github page</tag>
      </tags>
  </entry>
  <entry>
    <title>python并行处理</title>
    <url>/archives/a448f9a6.html</url>
    <content><![CDATA[<h1 id="基于进程的并行"><a href="#基于进程的并行" class="headerlink" title="基于进程的并行"></a>基于进程的并行</h1><h2 id="方法1-multiprocessing"><a href="#方法1-multiprocessing" class="headerlink" title="方法1: multiprocessing"></a>方法1: multiprocessing</h2><a id="more"></a>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> multiprocessing <span class="keyword">as</span> mp</span><br><span class="line"><span class="comment"># map与imap,对于很长的迭代对象，可能消耗很多内存。可以考虑使用 imap()</span></span><br><span class="line"><span class="comment"># map(func, iterable[, chunksize])</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">twotimes</span>(<span class="params">i</span>):</span></span><br><span class="line">    <span class="keyword">return</span> i * <span class="number">2</span></span><br><span class="line">pool = mp.Pool(processes = mp.cpu_count())</span><br><span class="line">results = pool.<span class="built_in">map</span>(twotimes, [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">print(results)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="方法2-Parallel"><a href="#方法2-Parallel" class="headerlink" title="方法2: Parallel"></a>方法2: Parallel</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> joblib <span class="keyword">import</span> Parallel, delayed, cpu_count</span><br><span class="line">batches = Parallel(n_jobs=cpu_count() - <span class="number">1</span>)(</span><br><span class="line">    delayed(extract)(i, br, bug_reports, java_src_dict)</span><br><span class="line">    <span class="keyword">for</span> i, br <span class="keyword">in</span> <span class="built_in">enumerate</span>(bug_reports)</span><br><span class="line">)</span><br><span class="line">features = [row <span class="keyword">for</span> batch <span class="keyword">in</span> batches <span class="keyword">for</span> row <span class="keyword">in</span> batch]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="方法3-pathos-pools"><a href="#方法3-pathos-pools" class="headerlink" title="方法3: pathos.pools"></a>方法3: pathos.pools</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pathos.pools <span class="keyword">as</span> pp</span><br></pre></td></tr></table></figure>
<h2 id="方法4-numba"><a href="#方法4-numba" class="headerlink" title="方法4: numba"></a>方法4: numba</h2><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol>
<li><a href="https://docs.python.org/zh-cn/3.8/library/multiprocessing.html">multiprocessing — 基于进程的并行</a></li>
<li><a href="https://blog.csdn.net/weixin_42001089/article/details/88843152?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-3.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-3.control">python 并行化：加快数据的处理</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/46378282">python并行计算（上）：pathos模块</a></li>
<li><a href="https://www.jianshu.com/p/69d9d7e37bc5">加速python运行-numba</a></li>
</ol>
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>并行处理</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>python执行cmd命令</title>
    <url>/archives/1012268b.html</url>
    <content><![CDATA[<p>我们通常可以使用os模块的命令进行执行cmd</p>
<h2 id="方法1：os-system"><a href="#方法1：os-system" class="headerlink" title="方法1：os.system"></a>方法1：os.system</h2><a id="more"></a>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># os.system(执行的指令)</span></span><br><span class="line">code = os.system(<span class="string">&#x27;ls&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="方法2-os-popen"><a href="#方法2-os-popen" class="headerlink" title="方法2: os.popen"></a>方法2: os.popen</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># os.popen(执行的指令)</span></span><br><span class="line">code = os.popen(<span class="string">&#x27;ls&#x27;</span>)</span><br><span class="line">code.read() <span class="keyword">or</span> code.readlines()</span><br></pre></td></tr></table></figure>
<h2 id="两者区别"><a href="#两者区别" class="headerlink" title="两者区别"></a>两者区别</h2><ul>
<li>system返回指令执行的结果，0表示执行成功，反之则为错误代码，这是系统依赖(system-dependent)的。system无法获取指令输出的信息。</li>
<li>popen可以获取输出的信息内容，它是一个文件对象，可以通过 .read() 去读取</li>
</ul>
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>cmd</tag>
      </tags>
  </entry>
  <entry>
    <title>python数组扩充</title>
    <url>/archives/13c6676c.html</url>
    <content><![CDATA[<h1 id="数组扩充"><a href="#数组扩充" class="headerlink" title="数组扩充"></a>数组扩充</h1><p>用repeat和tile扩充数组元素，例如</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>data = np.array([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = np.tile(data,(<span class="number">2</span>,<span class="number">2</span>))</span><br><span class="line">array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>],</span><br><span class="line">       [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a=np.array([[<span class="number">10</span>,<span class="number">20</span>],[<span class="number">30</span>,<span class="number">40</span>]])  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a.repeat([<span class="number">3</span>,<span class="number">2</span>],axis=<span class="number">0</span>)</span><br><span class="line">array([[<span class="number">10</span>, <span class="number">20</span>],  </span><br><span class="line">       [<span class="number">10</span>, <span class="number">20</span>],  </span><br><span class="line">       [<span class="number">10</span>, <span class="number">20</span>],  </span><br><span class="line">       [<span class="number">30</span>, <span class="number">40</span>],  </span><br><span class="line">       [<span class="number">30</span>, <span class="number">40</span>]]) </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a.repeat([<span class="number">3</span>,<span class="number">2</span>],axis=<span class="number">1</span>) </span><br><span class="line">array([[<span class="number">10</span>, <span class="number">10</span>, <span class="number">10</span>, <span class="number">20</span>, <span class="number">20</span>],</span><br><span class="line">       [<span class="number">30</span>, <span class="number">30</span>, <span class="number">30</span>, <span class="number">40</span>, <span class="number">40</span>]])</span><br></pre></td></tr></table></figure>
<h1 id="torch数组扩充"><a href="#torch数组扩充" class="headerlink" title="torch数组扩充"></a>torch数组扩充</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> torch</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>data = torch.Tensor([[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">2</span>,<span class="number">3</span>]])</span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">2.</span>],</span><br><span class="line">        [<span class="number">2.</span>, <span class="number">3.</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = data.repeat(<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">2.</span>, <span class="number">1.</span>, <span class="number">2.</span>],</span><br><span class="line">        [<span class="number">2.</span>, <span class="number">3.</span>, <span class="number">2.</span>, <span class="number">3.</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = a.view(-<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">2.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">2.</span>],</span><br><span class="line">        [<span class="number">2.</span>, <span class="number">3.</span>],</span><br><span class="line">        [<span class="number">2.</span>, <span class="number">3.</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c = data.repeat(<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">2.</span>],</span><br><span class="line">        [<span class="number">2.</span>, <span class="number">3.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">2.</span>],</span><br><span class="line">        [<span class="number">2.</span>, <span class="number">3.</span>]])</span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>数组扩充</tag>
      </tags>
  </entry>
  <entry>
    <title>python标准化方法</title>
    <url>/archives/af7b2e2a.html</url>
    <content><![CDATA[<h1 id="第一类Normalization"><a href="#第一类Normalization" class="headerlink" title="第一类Normalization"></a>第一类Normalization</h1><h2 id="零一标准化"><a href="#零一标准化" class="headerlink" title="零一标准化"></a>零一标准化</h2><p>对数组列或行进行零一标准化，区间范围为0，1<br>对行进行零一标准化</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> minmax_scale</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>data = [[-<span class="number">1</span>, <span class="number">2</span>], [-<span class="number">0.5</span>, <span class="number">6</span>], [<span class="number">0</span>, <span class="number">10</span>], [<span class="number">1</span>, <span class="number">18</span>]]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>processed_data = minmax_scale(data,axis=<span class="number">1</span>)</span><br><span class="line">array([[<span class="number">0.</span>, <span class="number">1.</span>],</span><br><span class="line">       [<span class="number">0.</span>, <span class="number">1.</span>],</span><br><span class="line">       [<span class="number">0.</span>, <span class="number">1.</span>],</span><br><span class="line">       [<span class="number">0.</span>, <span class="number">1.</span>]])</span><br></pre></td></tr></table></figure>
<p>MinMaxScaler调用了minmax_scale，对列进行零一标准化</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>data = [[-<span class="number">1</span>, <span class="number">2</span>], [-<span class="number">0.5</span>, <span class="number">6</span>], [<span class="number">0</span>, <span class="number">10</span>], [<span class="number">1</span>, <span class="number">18</span>]]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>scaler = MinMaxScaler()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>scaler.fit(data)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>processed_data = scaler.transform(data)</span><br><span class="line">array([[<span class="number">0.</span>  , <span class="number">0.</span>  ],</span><br><span class="line">       [<span class="number">0.25</span>, <span class="number">0.25</span>],</span><br><span class="line">       [<span class="number">0.5</span> , <span class="number">0.5</span> ],</span><br><span class="line">       [<span class="number">1.</span>  , <span class="number">1.</span>  ]])</span><br></pre></td></tr></table></figure>
<h2 id="Z-score-normalization"><a href="#Z-score-normalization" class="headerlink" title="Z-score normalization"></a>Z-score normalization</h2><p>使用sklearn.preprocessing.scale()函数，可以直接将给定数据进行标准化。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X = np.array([[ <span class="number">1.</span>, -<span class="number">1.</span>,  <span class="number">2.</span>],</span><br><span class="line"><span class="meta">... </span>              [ <span class="number">2.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line"><span class="meta">... </span>              [ <span class="number">0.</span>,  <span class="number">1.</span>, -<span class="number">1.</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X_scaled = preprocessing.scale(X)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X_scaled                                          </span><br><span class="line">array([[ <span class="number">0.</span>  ..., -<span class="number">1.22</span>...,  <span class="number">1.33</span>...],</span><br><span class="line">       [ <span class="number">1.22</span>...,  <span class="number">0.</span>  ..., -<span class="number">0.26</span>...],</span><br><span class="line">       [-<span class="number">1.22</span>...,  <span class="number">1.22</span>..., -<span class="number">1.06</span>...]])</span><br><span class="line">&gt;&gt;&gt;<span class="comment">#处理后数据的均值和方差</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X_scaled.mean(axis=<span class="number">0</span>)</span><br><span class="line">array([ <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X_scaled.std(axis=<span class="number">0</span>)</span><br><span class="line">array([ <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>])</span><br></pre></td></tr></table></figure>
<h1 id="第二类Normalization"><a href="#第二类Normalization" class="headerlink" title="第二类Normalization"></a>第二类Normalization</h1><p>第二种Normalization对于每个样本缩放到单位范数（每个样本的范数为1），主要有L1-normalization（L1范数）、L2-normalization（L2范数）等。<br>Normalization主要思想是对每个样本计算其p-范数，然后对该样本中每个元素除以该范数，这样处理的结果是使得每个处理后样本的p-范数（比如l1-norm,l2-norm）等于1。<br>p-范数的计算公式：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">\|X\|_&#123;p&#125;&#x3D;\left(\left(\left|x_&#123;1&#125;\right|\right)^&#123;p&#125;+\left(\left|x_&#123;2&#125;\right|\right)^&#123;p&#125;+\ldots+\left(\left|x_&#123;n&#125;\right|\right)^&#123;p&#125;\right)^&#123;\frac&#123;1&#125;&#123;p&#125;&#125;</span><br></pre></td></tr></table></figure>
<p>该方法主要应用于文本分类和聚类中。例如，对于两个TF-IDF向量的l2-norm进行点积，就可以得到这两个向量的余弦相似性。</p>
<ul>
<li>可以使用preprocessing.normalize()函数对指定数据进行转换：<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; X &#x3D; [[ 1., -1.,  2.],</span><br><span class="line">...      [ 2.,  0.,  0.],</span><br><span class="line">...      [ 0.,  1., -1.]]</span><br><span class="line">&gt;&gt;&gt; X_normalized &#x3D; preprocessing.normalize(X, norm&#x3D;&#39;l2&#39;)</span><br><span class="line">&gt;&gt;&gt; X_normalized                                      </span><br><span class="line">array([[ 0.40..., -0.40...,  0.81...],</span><br><span class="line">       [ 1.  ...,  0.  ...,  0.  ...],</span><br><span class="line">       [ 0.  ...,  0.70..., -0.70...]])</span><br><span class="line">&gt;&gt;&gt; X_normalized &#x3D; preprocessing.normalize(X, norm&#x3D;&#39;l1&#39;)</span><br><span class="line">array([[ 0.25, -0.25,  0.5 ],</span><br><span class="line">       [ 1.  ,  0.  ,  0.  ],</span><br><span class="line">       [ 0.  ,  0.5 , -0.5 ]])</span><br></pre></td></tr></table></figure>
<h2 id="一行或一列累加标准化"><a href="#一行或一列累加标准化" class="headerlink" title="一行或一列累加标准化"></a>一行或一列累加标准化</h2></li>
<li>使用preprocessing.normalize(X, norm=’l1’)<ul>
<li>可以避免全零行的影响</li>
<li>可以使用稀疏矩阵，必须CSR format </li>
</ul>
</li>
</ul>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol>
<li><a href="https://blog.csdn.net/u011092188/article/details/78174804">Normalization(标准化)的原理和实现详解</a></li>
</ol>
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>标准化</tag>
      </tags>
  </entry>
  <entry>
    <title>python添加进度条</title>
    <url>/archives/83a60a30.html</url>
    <content><![CDATA[<h2 id="方法1-tqdm"><a href="#方法1-tqdm" class="headerlink" title="方法1: tqdm"></a>方法1: tqdm</h2><ol>
<li>通过tqdm实现</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># tqdm(list)方法可以传入任意一种list,比如数组</span></span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> tqdm(<span class="built_in">range</span>(<span class="number">1000</span>)):</span><br><span class="line">	<span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<a id="more"></a>
<ol start="2">
<li>通过trange实现<br>trange(i) 是 tqdm(range(i)) 的简单写法</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> trange</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> trange(<span class="number">100</span>):</span><br><span class="line">	<span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意，tqdm是任务开始时刷新进度条</p>
</blockquote>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol>
<li><a href="https://blog.csdn.net/zkp_987/article/details/81748098">tqdm介绍及常用方法</a></li>
</ol>
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>进度条</tag>
      </tags>
  </entry>
  <entry>
    <title>python相似度计算</title>
    <url>/archives/f8cf55af.html</url>
    <content><![CDATA[]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>相似度计算</tag>
      </tags>
  </entry>
  <entry>
    <title>ubuntu perl运行踩坑汇总</title>
    <url>/archives/ee2c00b4.html</url>
    <content><![CDATA[<p>这些是我在运行一个pl脚本时遇到的一些错误，通过安装缺失的包解决了。</p>
<ol>
<li>Can’t locate DBI.pm in @INC (you may need to install the DBI module)</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo apt-get install libdbi-perl</span><br></pre></td></tr></table></figure>
<a id="more"></a>
<ol start="2">
<li></li>
</ol>
]]></content>
      <categories>
        <category>Perl</category>
        <category>ubuntu</category>
      </categories>
      <tags>
        <tag>Perl</tag>
        <tag>ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title>ubuntu安装mysql和简单操作</title>
    <url>/archives/828b22fd.html</url>
    <content><![CDATA[<h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo apt-get install mysql-server          &#x2F;&#x2F;服务端</span><br><span class="line">sudo apt-get install mysql-client          &#x2F;&#x2F;客户端</span><br><span class="line">sudo apt-get install libmysqlclient-dev  &#x2F;&#x2F;程序编译时链接的库</span><br><span class="line">sudo apt-get install mysql-workbench  &#x2F;&#x2F;可视化工具</span><br></pre></td></tr></table></figure>
<p>安装过程中会提示设置密码什么的，注意设置了不要忘了，安装完成之后可以使用如下命令来检查是否安装成功：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo netstat -tap | grep mysql</span><br></pre></td></tr></table></figure>
<a id="more"></a>
<h1 id="登陆"><a href="#登陆" class="headerlink" title="登陆"></a>登陆</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mysql -u root -p</span><br></pre></td></tr></table></figure>
<p>或者这样登陆</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#服务启动后端口查询</span><br><span class="line">sudo netstat -anp | grep mysql</span><br><span class="line"></span><br><span class="line">#连接数据库</span><br><span class="line">mysql -h 127.0.0.1 -P 3306 -uroot -p123456</span><br><span class="line">#-h为远程IP，-P为端口号，-u为用户名，-p为密码</span><br></pre></td></tr></table></figure>
<h2 id="可视化工具推荐"><a href="#可视化工具推荐" class="headerlink" title="可视化工具推荐"></a>可视化工具推荐</h2><p>Navicat Premiun，适合win和mac，可远程连接服务器数据库</p>
<h1 id="sql简单语法"><a href="#sql简单语法" class="headerlink" title="sql简单语法"></a>sql简单语法</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">show databases;  # 查看当前数据库</span><br><span class="line">create database library; # 创建数据库</span><br><span class="line">use library; # 选择数据库</span><br><span class="line">show tables; # 查看数据表</span><br><span class="line">exit; # 退出</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>sql</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>ubuntu查看文件编码类型</title>
    <url>/archives/e51b08cc.html</url>
    <content><![CDATA[<h2 id="方法1-file-i-filename"><a href="#方法1-file-i-filename" class="headerlink" title="方法1: file -i filename"></a>方法1: file -i filename</h2><a id="more"></a>]]></content>
      <categories>
        <category>ubuntu</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title>ubuntu系统深度学习环境搭建</title>
    <url>/archives/923d283b.html</url>
    <content><![CDATA[<p>首先，查看ubuntu版本可以用下面的指令</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &#x2F;proc&#x2F;version</span><br></pre></td></tr></table></figure>
<a id="more"></a>

<h1 id="使用conda安装"><a href="#使用conda安装" class="headerlink" title="使用conda安装"></a>使用conda安装</h1><p>这是最简洁的安装方式</p>
<p>安装tensorflow-gpu</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">conda create -n tf-gpu tensorflow-gpu</span><br><span class="line">conda activate tf-gpu</span><br></pre></td></tr></table></figure>
<p>安装pytorch</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">conda install pytorch&#x3D;&#x3D;1.4.0 torchvision&#x3D;&#x3D;0.5.0 cudatoolkit&#x3D;10.1 -c pytorch</span><br><span class="line"># or</span><br><span class="line">conda install pytorch torchvision -c pytorch</span><br></pre></td></tr></table></figure>
<p>查看cuda版本</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">conda list</span><br></pre></td></tr></table></figure>
<hr>
<p><strong>之后内容废弃</strong></p>
<h1 id="ubuntu18-04安装tensorflow"><a href="#ubuntu18-04安装tensorflow" class="headerlink" title="ubuntu18.04安装tensorflow"></a>ubuntu18.04安装tensorflow</h1><p>安装tensorflow，参考<a href="https://www.tensorflow.org/install/gpu">https://www.tensorflow.org/install/gpu</a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Add NVIDIA package repositories</span><br><span class="line">wget https:&#x2F;&#x2F;developer.download.nvidia.com&#x2F;compute&#x2F;cuda&#x2F;repos&#x2F;ubuntu1804&#x2F;x86_64&#x2F;cuda-ubuntu1804.pin</span><br><span class="line">sudo mv cuda-ubuntu1804.pin &#x2F;etc&#x2F;apt&#x2F;preferences.d&#x2F;cuda-repository-pin-600</span><br><span class="line">sudo apt-key adv --fetch-keys https:&#x2F;&#x2F;developer.download.nvidia.com&#x2F;compute&#x2F;cuda&#x2F;repos&#x2F;ubuntu1804&#x2F;x86_64&#x2F;7fa2af80.pub</span><br><span class="line">sudo add-apt-repository &quot;deb https:&#x2F;&#x2F;developer.download.nvidia.com&#x2F;compute&#x2F;cuda&#x2F;repos&#x2F;ubuntu1804&#x2F;x86_64&#x2F; &#x2F;&quot;</span><br><span class="line">sudo apt-get update</span><br><span class="line"></span><br><span class="line">wget http:&#x2F;&#x2F;developer.download.nvidia.com&#x2F;compute&#x2F;machine-learning&#x2F;repos&#x2F;ubuntu1804&#x2F;x86_64&#x2F;nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.deb</span><br><span class="line"></span><br><span class="line">sudo apt install .&#x2F;nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.deb</span><br><span class="line">sudo apt-get update</span><br><span class="line"></span><br><span class="line"># Install NVIDIA driver</span><br><span class="line">sudo apt-get install --no-install-recommends nvidia-driver-450</span><br><span class="line"># Reboot. Check that GPUs are visible using the command: nvidia-smi</span><br><span class="line"></span><br><span class="line">wget https:&#x2F;&#x2F;developer.download.nvidia.com&#x2F;compute&#x2F;machine-learning&#x2F;repos&#x2F;ubuntu1804&#x2F;x86_64&#x2F;libnvinfer7_7.1.3-1+cuda11.0_amd64.deb</span><br><span class="line">sudo apt install .&#x2F;libnvinfer7_7.1.3-1+cuda11.0_amd64.deb</span><br><span class="line">sudo apt-get update</span><br><span class="line"></span><br><span class="line"># Install development and runtime libraries (~4GB)</span><br><span class="line">sudo apt-get install --no-install-recommends \</span><br><span class="line">    cuda-11-0 \</span><br><span class="line">    libcudnn8&#x3D;8.0.4.30-1+cuda11.0  \</span><br><span class="line">    libcudnn8-dev&#x3D;8.0.4.30-1+cuda11.0</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Install TensorRT. Requires that libcudnn8 is installed above.</span><br><span class="line">sudo apt-get install -y --no-install-recommends libnvinfer7&#x3D;7.1.3-1+cuda11.0 \</span><br><span class="line">    libnvinfer-dev&#x3D;7.1.3-1+cuda11.0 \</span><br><span class="line">    libnvinfer-plugin7&#x3D;7.1.3-1+cuda11.0</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="匹配关系"><a href="#匹配关系" class="headerlink" title="匹配关系"></a>匹配关系</h2><p>tensorflow匹配关系见网址：<a href="https://www.tensorflow.org/install/source_windows">https://www.tensorflow.org/install/source_windows</a></p>
<h2 id="tensroflow-GPU测试代码"><a href="#tensroflow-GPU测试代码" class="headerlink" title="tensroflow GPU测试代码"></a>tensroflow GPU测试代码</h2><figure class="highlight diff"><table><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line"><span class="deletion">- print(tf.test.is_gpu_available()) # 之前的版本，待废弃</span></span><br><span class="line"><span class="addition">+ tf.config.list_physical_devices(&#x27;GPU&#x27;)</span></span><br></pre></td></tr></table></figure>
<h1 id="ubuntu18-04安装pytorch"><a href="#ubuntu18-04安装pytorch" class="headerlink" title="ubuntu18.04安装pytorch"></a>ubuntu18.04安装pytorch</h1><p>在安装好nvidia驱动的基础上，可以直接安装</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">conda install pytorch torchvision -c pytorch</span><br></pre></td></tr></table></figure>
<h2 id="匹配关系-1"><a href="#匹配关系-1" class="headerlink" title="匹配关系"></a>匹配关系</h2><p>这里是pytorch和cudatoolkit版本对应关系：<a href="https://pytorch.org/get-started/previous-versions/">https://pytorch.org/get-started/previous-versions/</a></p>
<table>
<thead>
<tr>
<th>CUDA版本</th>
<th>可用PyTorch版本</th>
</tr>
</thead>
<tbody><tr>
<td>7.5</td>
<td>0.4.1 ，0.3.0， 0.2.0，0.1.12-0.1.6</td>
</tr>
<tr>
<td>8.0</td>
<td>1.1.0，1.0.0 ，0.4.1</td>
</tr>
<tr>
<td>9.0</td>
<td>1.1.0，1.0.1, 1.0.0，0.4.1</td>
</tr>
<tr>
<td>9.2</td>
<td>1.6.0，1.5.0，1.4.0，1.2.0，0.4.1</td>
</tr>
<tr>
<td>10.0</td>
<td>1.2.0，1.1.0，1.0.1 ,1.0.0</td>
</tr>
<tr>
<td>10.1</td>
<td>1.6.0，1.5.0， 1.4.0，1.3.0</td>
</tr>
<tr>
<td>10.2</td>
<td>1.6.0，1.5.0</td>
</tr>
<tr>
<td>11.0</td>
<td>1.7.0</td>
</tr>
</tbody></table>
<h2 id="pytorch-GPU测试代码"><a href="#pytorch-GPU测试代码" class="headerlink" title="pytorch GPU测试代码"></a>pytorch GPU测试代码</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import torch</span><br><span class="line">print(torch.cuda.is_available())</span><br></pre></td></tr></table></figure>
<hr>
<h1 id="Nvidia驱动、cuda和cuDNN安装"><a href="#Nvidia驱动、cuda和cuDNN安装" class="headerlink" title="Nvidia驱动、cuda和cuDNN安装"></a>Nvidia驱动、cuda和cuDNN安装</h1><h2 id="NVIDIA-驱动安装"><a href="#NVIDIA-驱动安装" class="headerlink" title="NVIDIA 驱动安装"></a>NVIDIA 驱动安装</h2><h2 id="CUDA安装"><a href="#CUDA安装" class="headerlink" title="CUDA安装"></a>CUDA安装</h2><p>首先贴一张CUDA和驱动版本的对应表，具体可见<a href="https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html#abstract">https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html#abstract</a>。<br><img src="http://ww1.sinaimg.cn/large/006ltHaXgy1gns49hgbu1j315m0rqaf4.jpg" alt="QQ20210218-233600@2x.png"></p>
<p>去官网上 下载和驱动对应的cuda文件<a href="https://developer.nvidia.com/cuda-toolkit-archive">https://developer.nvidia.com/cuda-toolkit-archive</a>，需要注册一个账号。</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol>
<li><a href="https://www.cnblogs.com/carle-09/p/11252814.html">Ubuntu系统—安NVIDIA 驱动后  CUDA+cuDNN 安装</a></li>
<li><a href="https://www.cnblogs.com/Wanggcong/p/12625540.html">pytorch版本，cuda版本，系统cuda版本查询和对应关系</a></li>
<li><a href="https://www.cnblogs.com/sunshe35/articles/12808780.html">彻底搞定tensorflow-GPU环境(史上最全)</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/52498335">conda安装tensorflow和pytorch</a></li>
</ol>
]]></content>
      <categories>
        <category>ubuntu</category>
      </categories>
      <tags>
        <tag>cuda</tag>
        <tag>cuDNN</tag>
      </tags>
  </entry>
  <entry>
    <title>ubuntu终端配置代理</title>
    <url>/archives/6a15ee01.html</url>
    <content><![CDATA[<h1 id="终端代理配置"><a href="#终端代理配置" class="headerlink" title="终端代理配置"></a>终端代理配置</h1><h2 id="临时"><a href="#临时" class="headerlink" title="临时"></a>临时</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">export https_proxy&#x3D;https:&#x2F;&#x2F;用户名:密码@代理地址:代理端口</span><br><span class="line">export http_proxy&#x3D;http:&#x2F;&#x2F;用户名:密码@代理地址:代理端口</span><br></pre></td></tr></table></figure>
<h2 id="永久"><a href="#永久" class="headerlink" title="永久"></a>永久</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># gedit ~&#x2F;.bashrc 在.bashrc文件末尾添加如下内容，或者在&#x2F;etc&#x2F;environment中</span><br><span class="line">export http_proxy&#x3D;http:&#x2F;&#x2F;用户名:密码@地址:端口&#x2F;</span><br><span class="line">export https_proxy&#x3D;http:&#x2F;&#x2F;用户名:密码@地址:端口&#x2F;</span><br><span class="line">export ftp_proxy&#x3D;http:&#x2F;&#x2F;用户名:密码@地址:端口&#x2F;</span><br><span class="line"># sudo gedit &#x2F;etc&#x2F;apt&#x2F;apt.conf 在apt.conf文件中加入下面这行</span><br><span class="line">Acquire::http::proxy &quot;http:&#x2F;&#x2F;用户名:密码@地址:端口&quot;;</span><br><span class="line">Acquire::ftp::proxy &quot;http:&#x2F;&#x2F;用户名:密码@地址:端口&quot;;</span><br><span class="line">Acquire::https::proxy &quot;http:&#x2F;&#x2F;用户名:密码@地址:端口&quot;;</span><br></pre></td></tr></table></figure>
<a id="more"></a>
<h1 id="配置V2ray-socks5"><a href="#配置V2ray-socks5" class="headerlink" title="配置V2ray socks5"></a>配置V2ray socks5</h1><h2 id="在ubuntu配置v2ray客户端"><a href="#在ubuntu配置v2ray客户端" class="headerlink" title="在ubuntu配置v2ray客户端"></a>在ubuntu配置v2ray客户端</h2><p>首先下载脚本:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wget https:&#x2F;&#x2F;github.com&#x2F;v2fly&#x2F;fhs-install-v2ray&#x2F;blob&#x2F;master&#x2F;install-dat-release.sh</span><br></pre></td></tr></table></figure>
<p>然后执行脚本安装 V2Ray:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo bash install-dat-release.sh</span><br></pre></td></tr></table></figure>
<p>复制配置文件config.json到**/usr/local/etc/v2ray/config.json**,可以直接从windows或mac的v2rayN客户端夹中直接复制过来.</p>
<p>启动v2ray服务</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl restart v2ray</span><br></pre></td></tr></table></figure>
<p>socks5代理已经启动, 默认端口是1080, (socks5://127.0.0.1:1080).</p>
<h2 id="配置http代理-privoxy"><a href="#配置http代理-privoxy" class="headerlink" title="配置http代理 privoxy"></a>配置http代理 privoxy</h2><p>有些命令行工具只能使用http代理, 不能使用socks5代理, 因此需要用privoxy把socks5代理转换为http代理.</p>
<p>安装privoxy</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo apt install -y privoxy</span><br></pre></td></tr></table></figure>
<p>修改配置文件/etc/privoxy/config</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">listen-address  :10809</span><br><span class="line">forward-socks5    &#x2F;    127.0.0.1:10808  .</span><br></pre></td></tr></table></figure>
<p>启动privoxy服务</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl restart privoxy</span><br></pre></td></tr></table></figure>
<p>http代理已经启动, 默认端口是10809, (<a href="http://127.0.0.1:10809/">http://127.0.0.1:10809</a>).</p>
<h2 id="配置proxychains"><a href="#配置proxychains" class="headerlink" title="配置proxychains"></a>配置proxychains</h2><p>有些linux命令行工具没有配置代理的方法, 可以用proxychains强制应用使用代理网络.</p>
<p>安装proxychains</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo apt install -y proxychains</span><br></pre></td></tr></table></figure>
<p>修改配置文件/etc/proxychains.conf最后一行</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">socks5  127.0.0.1 10808</span><br></pre></td></tr></table></figure>
<p>使用proxychains方法, 在命令前加上proxychains, 如:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">proxychains apt update</span><br></pre></td></tr></table></figure>
<h2 id="python-pip使用http代理加速"><a href="#python-pip使用http代理加速" class="headerlink" title="python pip使用http代理加速"></a>python pip使用http代理加速</h2><p>方法1:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pip3 install -r requirement.txt --proxy http:&#x2F;&#x2F;127.0.0.1:10809</span><br></pre></td></tr></table></figure>
<p>方法2:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">proxychains pip3 install -r requirement.txt</span><br></pre></td></tr></table></figure>
<p>git使用http代理加速</p>
<p>方法1:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git config --global http.proxy http:&#x2F;&#x2F;127.0.0.1:10809</span><br><span class="line">git config --global https.proxy http:&#x2F;&#x2F;127.0.0.1:10809</span><br></pre></td></tr></table></figure>
<p>取消设置</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git config --global --unset http.proxy</span><br></pre></td></tr></table></figure>
<p>方法2:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">proxychains git clone https:&#x2F;&#x2F;github.com&#x2F;opencv&#x2F;opencv.git</span><br></pre></td></tr></table></figure>
<p>docker使用http代理加速</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;docker.service.d</span><br><span class="line">&#x2F;etc&#x2F;systemd&#x2F;system&#x2F;docker.service.d&#x2F;http-proxy.conf</span><br><span class="line">------</span><br><span class="line">[Service]</span><br><span class="line">Environment&#x3D;&quot;HTTP_PROXY&#x3D;http:&#x2F;&#x2F;127.0.0.1:10809&#x2F;&quot;</span><br><span class="line">------</span><br><span class="line"># systemctl daemon-reload</span><br><span class="line"># systemctl restart docker</span><br></pre></td></tr></table></figure>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol>
<li><a href="https://blog.51cto.com/laok8/2609755">在Ubuntu Linux中命令行工具使用代理v2ray privoxy proxychains学习</a></li>
</ol>
]]></content>
      <categories>
        <category>ubuntu</category>
      </categories>
      <tags>
        <tag>代理</tag>
      </tags>
  </entry>
  <entry>
    <title>vim个人配置记录</title>
    <url>/archives/fff3ae8c.html</url>
    <content><![CDATA[<h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><h2 id="spacevim安装"><a href="#spacevim安装" class="headerlink" title="spacevim安装"></a>spacevim安装</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -sLf https:&#x2F;&#x2F;spacevim.org&#x2F;cn&#x2F;install.sh | bash</span><br></pre></td></tr></table></figure>
<a id="more"></a>
<h2 id="配置修改"><a href="#配置修改" class="headerlink" title="配置修改"></a>配置修改</h2><p>修改文件.SpaceVim.dinit.toml</p>
<figure class="highlight diff"><table><tr><td class="code"><pre><span class="line">[[layers]]</span><br><span class="line">  name = &quot;lang#markdown&quot;</span><br></pre></td></tr></table></figure>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol>
<li><a href="https://spacevim.org/cn/">SpaceVim</a></li>
</ol>
]]></content>
      <categories>
        <category>软件使用</category>
      </categories>
      <tags>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title>【天赋树】一个期权交易员的自我修养 - 转载</title>
    <url>/archives/bf7d175a.html</url>
    <content><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="抱歉, 这个密码看着不太对, 请再试试." data-whm="抱歉, 这个文章不能被校验, 不过您还是能看看解密后的内容.">
  <script id="hbeData" type="hbeData" data-hmacdigest="51447b7130e8e4753e7a623ae5bb148c67d207844686b608d2dc43c3a71b66ce">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</script>
  <div class="hbe hbe-content">
    <div class="hbe hbe-input hbe-input-default">
      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">
      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">
        <span class="hbe hbe-input-label-content hbe-input-label-content-default">您好, 这里需要密码.</span>
      </label>
    </div>
  </div>
</div>
<script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      <categories>
        <category>交易</category>
        <category>期权</category>
      </categories>
      <tags>
        <tag>天赋树</tag>
      </tags>
  </entry>
  <entry>
    <title>使用hexo搭建个人博客</title>
    <url>/archives/ba7bb759.html</url>
    <content><![CDATA[<p>前言：本博客搭建时使用的nodejs版本为12.21.1，hexo版本为5.3.0，next版本为7.4.0，初次搭建推荐做一些文件改动时就测试一下(我到最后才发现hexo d居然出问题，艹)</p>
<a id="more"></a>

<h1 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h1><p>在开始一切之前，你必须已经：</p>
<ul>
<li>有一个github或gitee账号，没有的话去注册一个；</li>
<li>安装了node.js、npm，并了解相关基础知识</li>
</ul>
<p>本文所使用的环境：</p>
<ul>
<li><a href="mailto:&#x6e;&#111;&#x64;&#x65;&#x2e;&#106;&#115;&#x40;&#49;&#x32;&#46;&#x32;&#x30;&#x2e;&#49;">&#x6e;&#111;&#x64;&#x65;&#x2e;&#106;&#115;&#x40;&#49;&#x32;&#46;&#x32;&#x30;&#x2e;&#49;</a></li>
<li><a href="mailto:&#x68;&#x65;&#x78;&#111;&#64;&#53;&#46;&#51;&#x2e;&#x30;">&#x68;&#x65;&#x78;&#111;&#64;&#53;&#46;&#51;&#x2e;&#x30;</a></li>
<li><a href="mailto:&#110;&#x65;&#120;&#116;&#x40;&#55;&#46;&#x34;&#46;&#48;">&#110;&#x65;&#120;&#116;&#x40;&#55;&#46;&#x34;&#46;&#48;</a></li>
</ul>
<p>npm推荐使用国内源，速度方便快捷</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 设置成淘宝源</span><br><span class="line">npm config set registry https:&#x2F;&#x2F;registry.npm.taobao.org</span><br><span class="line"># 查看结果</span><br><span class="line">npm config get registry</span><br></pre></td></tr></table></figure>
<h1 id="使用hexo写博客"><a href="#使用hexo写博客" class="headerlink" title="使用hexo写博客"></a>使用hexo写博客</h1><h2 id="安装hexo"><a href="#安装hexo" class="headerlink" title="安装hexo"></a>安装hexo</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">npm install hexo-cli -g</span><br></pre></td></tr></table></figure>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol>
<li><a href="https://www.cnblogs.com/liuxianan/p/build-blog-website-by-hexo-github.html">使用hexo+github搭建免费个人博客详细教程</a></li>
<li><a href="https://github.com/hexojs/hexo">https://github.com/hexojs/hexo</a></li>
<li><a href="https://blog.csdn.net/qq_39207948/article/details/79449633">npm配置国内镜像资源+淘宝镜像</a></li>
</ol>
]]></content>
      <categories>
        <category>建站教程</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>github page</tag>
      </tags>
  </entry>
  <entry>
    <title>常用工具推荐</title>
    <url>/archives/ab83100f.html</url>
    <content><![CDATA[<p>仅记录我使用的一些比较方便的工具，留作备份</p>
<a id="more"></a>

<h1 id="win10"><a href="#win10" class="headerlink" title="win10"></a>win10</h1><ol>
<li>mobaxterm<br>本地电脑目录：/drives/下有所有盘符</li>
<li>vscode<br>markdown和latex等插件齐全。<br>markdown：Markdown All in One和Markdown Preview Enhanced</li>
<li>Mathpix Snip<br>latex公式识别神器</li>
<li>navicat<br>数据库可视化</li>
</ol>
]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>软件</tag>
      </tags>
  </entry>
  <entry>
    <title>永续合约套利 - 转载</title>
    <url>/archives/351b7a85.html</url>
    <content><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="抱歉, 这个密码看着不太对, 请再试试." data-whm="抱歉, 这个文章不能被校验, 不过您还是能看看解密后的内容.">
  <script id="hbeData" type="hbeData" data-hmacdigest="b4748a1a97e89329964ae3b9a8f3ede5fbe2b9b7c3147050b9f7d979b480a35f">c9633bf891dcd16dfc4a39c0845dabc3412a808e5bd9cf329164dc6296eef17504caecd8a7064441ffb6c138b87691bbf1fec5334ad76387d455334e9371c8957d5687aabd256ed62a42a7064d00b6ef70a9a1db04f09a45f457ea64b7491f09007cdccbbc0a807377fd7aea47228314f05ffeb9ae1bb3bd73b3fddc8e09eda845574777e768d8945f31e41f374345170bcf5741ef1429beb6332fa9a8e57d08e0023a508497547b1dec2ea547bde5ec33043c93bce562ca41c58ff6e7e494df0c0c5285c8cb49e7842c90ac0065569e561df0d393547eabb20fdb226c9fa3ec5777d769fe29e08d5fb01e2b0a11a8ad532ff653503c294d77b3e6343205d2228727f831f11a79250f88870ae31b0b5010ef9b163e4b76a3017c8ec93e511bd6de0bad6c612066a5887aa54037b9b7c33faba9b4966465cdba38d0bae76be55c74a79ff58a6c7a7aa4ae86bcc2704d3a9c7425f504dde9d621b8847239c377355f3012fe7363660fb9e6e7f942b48b467b1d622c7cf9df5ec74cc49c3f58bbdabc27dfe84f3d78c08ec25b00ed91b05622b8540113b3af9c2f52f7057023c1b8dd9137c475d7ac4f14f18599794655c6b1c5f388900c58c33e535248a43515ee788f7aafc6eaae48b1383f357f5a7a9270ca4ab759f1b1a31299d93b8e49b9a54e8b18bb0bdfc9cd7e75f4c17096a4b3eed755c49a2c1bd9dcfc4b08f4ad835a933ef07bf6a6d217a45661632aa554c21de98034c223aba4e96a0e7dbd0eaccabca2a26c9768cfa50347477c432398ca563471853e8a24abbec4472c8a8f18ddb1ea84efd6be9ab2fe47ce2b0ea0fc3bbcdf0b3a1fb2774020d5f23f417e850a621f993320503670802962260b6cd100dda57b19350f8741da3f5f3218ac4ec3d0179f63784aa635a7ed1afaf72040980398f00677bc4c449974f8a63aacc150f539bdb7f51517739260c654b8bb4495549297ff4a1ad026f447f4478d9116bb52a6c664e31c1191e3fdf0584bed7077ffdaf767d3a950ddc01b6a55675884f1880475f12d4380c88a2a333ce67d2c24168e557c0ab07b12590520bf71493f5cd88fea8858bfd069dbf9504b5539f6d76619093c663118e49c27f3bd70e59d5381fcd5ac73f8f07aea047af7b24efaed13b26f11e3361f0aacadcb5f1d84c94e349c03b84e95efa9ac05d5983357939c5ad167a1abe4e6974f9360ffe0aca0ed9c8c2d09b417d9c04537986bf5a4055b615b98765d872872893bfed080197b383060550d25c30bb1cb19de5c590f0b163f9b12e9ca1c7cf2e126aa75f444f926a7f77b938746e56cc41b460144e61727932760037475d584ea9dfb062eebf8b30c38a9989a75964f11adf545325a6bb460ea010fb79d356feccb7fa46c6429f9fd43e4ea05700b1968fd8ce3cdd4bd921420c560453ded07c1b235866f01e909f5d890100c2170df1be4809eb0af36f31face041319892aab33447bbc0b23a239c44c178cbd8139ac84df6fb990cff8f2bb8f0f196430c55986ba732cefb8b48695fd4d53e8dcb9c2ff58e3ffbe38392c237d155083f7f01495f554f43e498dcd163a4fa71e1cad0c5bdc8ed39ddaa4755bbcb370ae1715fada9f2758a6461488e0915a1f9e0970602487697f4fb7b73c68e68b61018b5911d9a0364f515ad97f163ad10e2b85511006e55c671b37b9e4cdbeb5fb1064efce4da947f7457e7e6abce8154c556343f9e0adf5d95ea3dfd3de75cb2a165df699ec691525c0f84f3f91a716fa3200eb4404550867d4f004a5573138f587d2ca7f62543516cd06e04827a4be596b41cfcef7386f017d160908ccb33b3f91a2ba79c9696de9d9719e6a2f55ad4180c95f73bab4cae352fdfc2f236b41b4587d3b9a6e499f4a1b415d8bc6306668ce9ce36fd7be2e5c7e016ee6b7d40ad45a9fc0b53dc486eb127705ed80204a61aeffdc5590824a7edc097b2f4d4e7d483babfe6350171a585354ece8b8e5908aa3557762ca3f99d201e02e1c8f7f3bc77120cd0350e5417d39b01b1dc9f0f34a433b8a3cef5d3f85ac0a055019944114acf63dcd9b24828b92964e71ab4375852a8a2c1806feb40e5ba718e</script>
  <div class="hbe hbe-content">
    <div class="hbe hbe-input hbe-input-default">
      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">
      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">
        <span class="hbe hbe-input-label-content hbe-input-label-content-default">您好, 这里需要密码.</span>
      </label>
    </div>
  </div>
</div>
<script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      <categories>
        <category>交易</category>
      </categories>
      <tags>
        <tag>套利</tag>
      </tags>
  </entry>
  <entry>
    <title>统计检验</title>
    <url>/archives/d831d399.html</url>
    <content><![CDATA[<h1 id="假设检验"><a href="#假设检验" class="headerlink" title="假设检验"></a>假设检验</h1><h2 id="Wilcoxon-秩和检验"><a href="#Wilcoxon-秩和检验" class="headerlink" title="Wilcoxon 秩和检验"></a>Wilcoxon 秩和检验</h2>]]></content>
  </entry>
  <entry>
    <title>ftx量化空间</title>
    <url>/archives/9060a5db.html</url>
    <content><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="抱歉, 这个密码看着不太对, 请再试试." data-whm="抱歉, 这个文章不能被校验, 不过您还是能看看解密后的内容.">
  <script id="hbeData" type="hbeData" data-hmacdigest="02bf989b047b22bf8cfcb5193b8209c30aa94df8583da5de7d4d0fda4e8b2465">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</script>
  <div class="hbe hbe-content">
    <div class="hbe hbe-input hbe-input-default">
      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">
      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">
        <span class="hbe hbe-input-label-content hbe-input-label-content-default">您好, 这里需要密码.</span>
      </label>
    </div>
  </div>
</div>
<script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      <categories>
        <category>交易</category>
      </categories>
      <tags>
        <tag>量化</tag>
      </tags>
  </entry>
  <entry>
    <title>pytorch loss function 总结</title>
    <url>/archives/8c962b5c.html</url>
    <content><![CDATA[<p>记录自己的学习过程，对深度学习目标函数自我总结。</p>
<a id="more"></a>
<h1 id="多标签分类（多目标分类）"><a href="#多标签分类（多目标分类）" class="headerlink" title="多标签分类（多目标分类）"></a>多标签分类（多目标分类）</h1><h2 id="BCELOSS"><a href="#BCELOSS" class="headerlink" title="BCELOSS"></a>BCELOSS</h2><p>等同于$torch.nn.functional.binary_cross_entropy$</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">\ell(x, y)&#x3D;L&#x3D;\left\&#123;l_&#123;1&#125;, \ldots, l_&#123;N&#125;\right\&#125;^&#123;\top&#125;, \quad l_&#123;n&#125;&#x3D;-w_&#123;n&#125;\left[y_&#123;n&#125; \cdot \log x_&#123;n&#125;+\left(1-y_&#123;n&#125;\right) \cdot \log \left(1-x_&#123;n&#125;\right)\right]</span><br></pre></td></tr></table></figure>
<p>用于自编码器的重构误差，目标y在0到1之间。若$x_n$为0或1，则不稳定，因为log(0)无限</p>
<blockquote>
<p>This is used for measuring the error of a reconstruction in for example an auto-encoder. Note that the targets yy should be numbers between 0 and 1.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> torch</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.Sigmoid()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>loss = nn.BCELoss()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">input</span> = torch.randn(<span class="number">3</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">tensor([ <span class="number">0.3216</span>, -<span class="number">1.3915</span>,  <span class="number">1.1682</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>target = torch.empty(<span class="number">3</span>).random_(<span class="number">2</span>)</span><br><span class="line">tensor([<span class="number">0.</span>, <span class="number">1.</span>, <span class="number">1.</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = loss(m(<span class="built_in">input</span>), target)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output.backward()</span><br></pre></td></tr></table></figure>
<h1 id="BCEWithLogitsLoss"><a href="#BCEWithLogitsLoss" class="headerlink" title="BCEWithLogitsLoss"></a>BCEWithLogitsLoss</h1><blockquote>
<p>This loss combines a Sigmoid layer and the BCELoss in one single class.</p>
</blockquote>
<p>等同于$torch.nn.functional.binary_cross_entropy_with_logits$<br>损失如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">\ell(x, y)&#x3D;L&#x3D;\left\&#123;l_&#123;1&#125;, \ldots, l_&#123;N&#125;\right\&#125;^&#123;\top&#125;, \quad l_&#123;n&#125;&#x3D;-w_&#123;n&#125;\left[y_&#123;n&#125; \cdot \log \sigma\left(x_&#123;n&#125;\right)+\left(1-y_&#123;n&#125;\right) \cdot \log \left(1-\sigma\left(x_&#123;n&#125;\right)\right)\right]</span><br></pre></td></tr></table></figure>
<p>目标范围在0到1之间。可用于多标签分类，损失如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">\ell_&#123;c&#125;(x, y)&#x3D;L_&#123;c&#125;&#x3D;\left\&#123;l_&#123;1, c&#125;, \ldots, l_&#123;N, c&#125;\right\&#125;^&#123;\top&#125;, \quad l_&#123;n, c&#125;&#x3D;-w_&#123;n, c&#125;\left[p_&#123;c&#125; y_&#123;n, c&#125; \cdot \log \sigma\left(x_&#123;n, c&#125;\right)+\left(1-y_&#123;n, c&#125;\right) \cdot \log (1-\sigma(x_&#123;n,c&#125;))]\right.</span><br></pre></td></tr></table></figure>
<p>其中，pos_weight提升正样例损失权重,维度与类个数相同，weight是对实例权重缩放，维度与nbatch相同</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>target = torch.ones([<span class="number">10</span>, <span class="number">64</span>], dtype=torch.float32)  <span class="comment"># 64 classes, batch size = 10</span></span><br><span class="line"><span class="number">10</span>*<span class="number">64</span>的全为<span class="number">1</span>的矩阵</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = torch.full([<span class="number">10</span>, <span class="number">64</span>], <span class="number">1.5</span>)  <span class="comment"># A prediction (logit)</span></span><br><span class="line"><span class="number">10</span>*<span class="number">64</span>的全为<span class="number">1.5</span>的矩阵</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>pos_weight = torch.ones([<span class="number">64</span>])  <span class="comment"># All weights are equal to 1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>criterion(output, target)  <span class="comment"># -log(sigmoid(1.5))</span></span><br><span class="line">tensor(<span class="number">0.2014</span>)</span><br></pre></td></tr></table></figure>
<h1 id="多分类"><a href="#多分类" class="headerlink" title="多分类"></a>多分类</h1><h2 id="CrossEntropyLoss"><a href="#CrossEntropyLoss" class="headerlink" title="CrossEntropyLoss"></a>CrossEntropyLoss</h2><blockquote>
<p>It is useful when training a classification problem with C classes. If provided, the optional argument weight should be a 1D Tensor assigning weight to each of the classes. This is particularly useful when you have an unbalanced training set.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>loss = nn.CrossEntropyLoss()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">input</span> = torch.randn(<span class="number">3</span>, <span class="number">5</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>target = torch.empty(<span class="number">3</span>, dtype=torch.long).random_(<span class="number">5</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = loss(<span class="built_in">input</span>, target)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output.backward()</span><br></pre></td></tr></table></figure>
<h2 id="NLLLoss"><a href="#NLLLoss" class="headerlink" title="NLLLoss"></a>NLLLoss</h2><p>NLLLoss的输入是一个对数概率向量和一个目标标签. 它不会为我们计算对数概率. 适合网络的最后一层是log_softmax. 损失函数 nn.CrossEntropyLoss() 与 NLLLoss() 相同, 唯一的不同是它为我们去做 softmax.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">m = nn.LogSoftmax()</span><br><span class="line">loss = nn.NLLLoss()</span><br><span class="line"><span class="comment"># input is of size nBatch x nClasses = 3 x 5</span></span><br><span class="line"><span class="built_in">input</span> = autograd.Variable(torch.randn(<span class="number">3</span>, <span class="number">5</span>), requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># each element in target has to have 0 &lt;= value &lt; nclasses</span></span><br><span class="line">target = autograd.Variable(torch.LongTensor([<span class="number">1</span>, <span class="number">0</span>, <span class="number">4</span>]))</span><br><span class="line">output = loss(m(<span class="built_in">input</span>), target)</span><br><span class="line">output.backward()</span><br></pre></td></tr></table></figure>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol>
<li><a href="https://www.cnblogs.com/kk17/p/10246324.html">pytorch loss function 总结</a></li>
<li><a href="https://pytorch-cn.readthedocs.io/zh/latest/">PyTorch中文文档</a></li>
<li><a href="https://pytorch.org/docs/stable/index.html">Pytorch官方文档</a></li>
</ol>
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>缺陷预测-软件度量</title>
    <url>/archives/5a3c8d60.html</url>
    <content><![CDATA[<p>参考部分百科[^1][^2]和英文文献</p>
<a id="more"></a>

<h1 id="Eccentricity-Hage"><a href="#Eccentricity-Hage" class="headerlink" title="Eccentricity[^Hage]"></a>Eccentricity[^Hage]</h1><h1 id="网络中心度量"><a href="#网络中心度量" class="headerlink" title="网络中心度量"></a>网络中心度量</h1><p>在大数据量下，经典的Closeness Centrality和Betwenness Centrality几乎都是不可计算的。我认为，在大数据的前提下，应该定义一些适合大规模计算的新的Centrality。</p>
<h2 id="度中心性（Degree-Centrality）-Freeman"><a href="#度中心性（Degree-Centrality）-Freeman" class="headerlink" title="度中心性（Degree Centrality）[^Freeman]"></a>度中心性（Degree Centrality）[^Freeman]</h2><p>度中心性（Degree Centrality）是在网络分析中刻画节点中心性（Centrality）的最直接度量指标。一个节点的节点度越大就意味着这个节点的度中心性越高，该节点在网络中就越重要。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">C_&#123;D&#125;\left(N_&#123;i&#125;\right)&#x3D;\sum_&#123;J&#x3D;1&#125;^&#123;g&#125; x_&#123;i j&#125;(i \neq j)</span><br></pre></td></tr></table></figure>
<p>其中$C_{D}\left(N_{i}\right)$表示节点i的度中心度，$\sum_{J=1}^{g} x_{i j}$用于计算节点i与其它g-1个j节点（i≠j，排除i与自身的联系；也就是说，主对角线的值可以忽略）之间的直接联系的数量。</p>
<h2 id="接近中心性（Closeness-Centrality）-Freeman"><a href="#接近中心性（Closeness-Centrality）-Freeman" class="headerlink" title="接近中心性（Closeness Centrality）[^Freeman]"></a>接近中心性（Closeness Centrality）[^Freeman]</h2><p>反映在网络中某一节点与其他节点之间的接近程度。如果节点到图中其它节点的最短距离都很小，那么我们认为该节点的Closeness Centrality高。</p>
<h2 id="中介中心性-中间中心性-Between-Centrality-Freeman"><a href="#中介中心性-中间中心性-Between-Centrality-Freeman" class="headerlink" title="中介中心性/中间中心性(Between Centrality) [^Freeman]"></a>中介中心性/中间中心性(Between Centrality) [^Freeman]</h2><p>以经过某个节点的最短路径数目来刻画节点重要性的指标。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">C_&#123;B&#125;(v)&#x3D;\sum_&#123;s \neq v \neq t \in V&#125; \frac&#123;\sigma_&#123;s t&#125;(v)&#125;&#123;\sigma_&#123;s t&#125;&#125;</span><br></pre></td></tr></table></figure>
<p>其中，$\sigma_{st}$表示的是节点s和t之间的最短路径的数量，而$\sigma_{st}(v)$是最短路径中经过节点v的数量。</p>
<h2 id="特征向量中心性（Eigenvector-Centrality）-Negre"><a href="#特征向量中心性（Eigenvector-Centrality）-Negre" class="headerlink" title="特征向量中心性（Eigenvector Centrality）[^Negre]"></a>特征向量中心性（Eigenvector Centrality）[^Negre]</h2><p>一个节点的重要性既取决于其邻居节点的数量（即该节点的度），也取决于其邻居节点的重要性。</p>
<p>[^1]: <a href="https://blog.csdn.net/wangjunliang/article/details/60468546">图论概念：Degree Centrality 和 Betweenness Centrality</a><br>[^2]: <a href="https://baike.baidu.com/item/%E5%BA%A6%E4%B8%AD%E5%BF%83%E6%80%A7/17510724?fr=aladdin">度中心性</a><br>[^Freeman]: L. C. Freeman, “Centrality in social networks conceptual clarification,” Social Networks, vol. 1, no. 3, pp. 215–239, 1978, doi: <a href="https://doi.org/10.1016/0378-8733(78)90021-7">https://doi.org/10.1016/0378-8733(78)90021-7</a>.<br>[^Negre]: C. F. A. Negre et al., “Eigenvector centrality for characterization of protein allosteric pathways,” in Proceedings of the National Academy of Sciences, 2018, vol. 115(52), pp. E12201–E12208, doi: 10.1073/pnas.1810452115.<br>[^Hage]: P. Hage and F. Harary, “Eccentricity and centrality in networks,” Social Networks, vol. 17, no. 1, pp. 57–63, 1995, doi: <a href="https://doi.org/10.1016/0378-8733(94)00248-9">https://doi.org/10.1016/0378-8733(94)00248-9</a>.</p>
]]></content>
      <categories>
        <category>缺陷预测</category>
      </categories>
      <tags>
        <tag>缺陷预测</tag>
        <tag>软件度量</tag>
      </tags>
  </entry>
  <entry>
    <title>Latex使用教程</title>
    <url>/archives/7a335556.html</url>
    <content><![CDATA[<h1 id="表格"><a href="#表格" class="headerlink" title="表格"></a>表格</h1><h2 id="tabincell"><a href="#tabincell" class="headerlink" title="tabincell"></a>tabincell</h2><p>使用方法</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">\tabincell&#123;l&#125;&#123;以方法为顶点，两方法\\引用构成的无向图的连通分支&#125;</span><br></pre></td></tr></table></figure>
<h2 id="multirow和multicol"><a href="#multirow和multicol" class="headerlink" title="multirow和multicol"></a>multirow和multicol</h2><p>\multirow{nrows}[bigstructs]{width}[fixup]{text}<br>nrows   设定所占用的行数。<br>bigstructs  此为可选项，主要是在你使用了 bigstruct 宏包时使用。<br>width  设定该栏文本的宽度。如果想让 LaTeX 自行决定文本的宽度，则用 * 即可。<br>fixup  此为可选项，主要用来调整文本的垂直位置。<br>text    所要排版的文本。可用 \ 来强迫换行。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">\begin&#123;tabular&#125;&#123;ccccrc&#125;</span><br><span class="line">  \hline</span><br><span class="line">  \textbf&#123;Datasets&#125; &amp; \textbf&#123;Projects&#125; &amp; \textbf&#123;Level&#125; &amp; \textbf&#123;\#Features&#125; &amp; \textbf&#123;\#Instances&#125; &amp; \textbf&#123;\#Faulty Instances (Percent)&#125; \\\hline %\hline</span><br><span class="line">    %\midrule</span><br><span class="line"></span><br><span class="line">   \multirow&#123;3&#125;&#123;*&#125;&#123;ReLink&#125; &amp; Apache &amp; \multirow&#123;3&#125;&#123;*&#125;&#123;File&#125;  &amp; \multirow&#123;3&#125;&#123;*&#125;&#123;26&#125; &amp; 194 &amp;\ 98 (50.52\%) \\</span><br><span class="line">   &amp; Safe &amp;  &amp;  &amp; 56 &amp;\ 22 (39.29\%) \\</span><br><span class="line">   &amp; ZXing &amp;  &amp;  &amp; 399 &amp; 118 (29.57\%) \\\hline %\hline</span><br><span class="line"></span><br><span class="line">    \multirow&#123;5&#125;&#123;*&#125;&#123;AEEEM&#125; &amp; EQ &amp; \multirow&#123;5&#125;&#123;*&#125;&#123;Class&#125;  &amp; \multirow&#123;5&#125;&#123;*&#125;&#123;61&#125; &amp; 324 &amp; 129 (39.8\%)\ \\</span><br><span class="line">   &amp; JDT &amp;  &amp;  &amp; 997 &amp; 206 (20.7\%) \\</span><br><span class="line">   &amp; LC &amp;  &amp;  &amp; 691 &amp;64 (9.3\%) \\</span><br><span class="line">   &amp; ML &amp;  &amp;  &amp; 1\hspace&#123;0.25ex&#125;862 &amp; 245 (13.2\%) \\</span><br><span class="line">   &amp; PDE &amp;  &amp;  &amp; 1\hspace&#123;0.25ex&#125;497 &amp; 209 (14.0\%) \\\hline</span><br><span class="line">  %\bottomrule</span><br><span class="line">\end&#123;tabular&#125;</span><br></pre></td></tr></table></figure>
<p>结果图：<br><img src="http://ww1.sinaimg.cn/large/006ltHaXly1gotapwipcsj30pn0ae0ui.jpg" alt="QQ截图20210323033228.png"></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">\multicolumn&#123;2&#125;&#123;c&#125;&#123;之前版本&#125;</span><br></pre></td></tr></table></figure>
<h2 id="表格画虚线"><a href="#表格画虚线" class="headerlink" title="表格画虚线"></a>表格画虚线</h2><p>The arydshln package offers you the \hdashline and \cdashline</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">\documentclass&#123;report&#125;</span><br><span class="line">\usepackage&#123;arydshln&#125;</span><br><span class="line"></span><br><span class="line">\begin&#123;document&#125;</span><br><span class="line"></span><br><span class="line">\begin&#123;tabular&#125;&#123;c:cc&#125;</span><br><span class="line">   column1a &amp; column2a &amp; column3a \\</span><br><span class="line">   column1b &amp; column2b   &amp; column3b\\ \hdashline</span><br><span class="line">   column1c &amp; column2c &amp; column3c \\ \cdashline&#123;1-2&#125;</span><br><span class="line">   column1d &amp; column2d &amp; column3d \\</span><br><span class="line">\end&#123;tabular&#125;</span><br><span class="line"></span><br><span class="line">\end&#123;document&#125;</span><br></pre></td></tr></table></figure>
<h2 id="表格画分开的线段"><a href="#表格画分开的线段" class="headerlink" title="表格画分开的线段"></a>表格画分开的线段</h2><p>使用\cmidrule(r){7-8}</p>
<h2 id="表格设置行间距列间距"><a href="#表格设置行间距列间距" class="headerlink" title="表格设置行间距列间距"></a>表格设置行间距列间距</h2><p>\renewcommand{\arraystretch}{1.3}%调行距<br>\setlength\tabcolsep{3pt}%调列距</p>
<h2 id="表格单元格设置背景颜色"><a href="#表格单元格设置背景颜色" class="headerlink" title="表格单元格设置背景颜色"></a>表格单元格设置背景颜色</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">\usepackage&#123;colortbl&#125;</span><br><span class="line"># \rowcolor&#123;颜色&#125;、\columncolor&#123;颜色&#125;、\cellcolor&#123;颜色&#125;</span><br><span class="line">\cellcolor&#123;lightgray&#125;</span><br></pre></td></tr></table></figure>
<h2 id="文字设置背景色"><a href="#文字设置背景色" class="headerlink" title="文字设置背景色"></a>文字设置背景色</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">\usepackage&#123;color&#125;%可以用于中文</span><br><span class="line">\colorbox&#123;yellow&#125;&#123;yellow background&#125;</span><br></pre></td></tr></table></figure>
<h2 id="表格单元格排列及长宽设置"><a href="#表格单元格排列及长宽设置" class="headerlink" title="表格单元格排列及长宽设置"></a>表格单元格排列及长宽设置</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">\usepackage&#123;array&#125;</span><br><span class="line">\begin&#123;tabular&#125;&#123;cp&#123;23em&#125;m&#123;2em&#125;b&#123;2em&#125;&#125;                              </span><br><span class="line">        \hline                                                     </span><br><span class="line">        横向居中&amp;居下&amp;居中&amp;居上\\                                  </span><br><span class="line">        \hline                                                     </span><br><span class="line">        a b c d e f g&amp; a b c d e f g&amp;a b c d e f g&amp;a b c d e f g\\ </span><br><span class="line">\hline                                                             </span><br><span class="line">\end&#123;tabular&#125;                                                      </span><br></pre></td></tr></table></figure>
<h2 id="表格重设表序号"><a href="#表格重设表序号" class="headerlink" title="表格重设表序号"></a>表格重设表序号</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># \setcounter&#123;page&#125;&#123;3&#125;</span><br><span class="line">\setcounter&#123;table&#125;&#123;1&#125; # 下个表格序号加一</span><br></pre></td></tr></table></figure>
<h1 id="有序列表和无序列表"><a href="#有序列表和无序列表" class="headerlink" title="有序列表和无序列表"></a>有序列表和无序列表</h1><p>有序列表使用方括号标号或自定义标号</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">\begin&#123;enumerate&#125;[label&#x3D;&#123;[\arabic*]&#125;]  %\setlength&#123;\itemsep&#125;&#123;0pt&#125;</span><br><span class="line">\item xxxxx   %[1] xxxxx</span><br><span class="line">\item yyyyyy  %[2] yyyyyy</span><br><span class="line">\item zzzzz   %[3] zzzzz</span><br><span class="line">\end&#123;enumerate&#125;</span><br></pre></td></tr></table></figure>
<p>其中，</p>
<ul>
<li>enumerate环境后面跟的参数label={[\arabic*]}即可使得列表以“方括号+阿拉伯数字”的形式编号；</li>
<li>在\begin{enumerate}[label={[\arabic*]}]后面跟\setlength{\itemsep}{0pt}可以设置当前列表环境里item条目之间的间距。</li>
<li>\arabic可以替换为\roman、\Roman、\Alph 或 \alph来表示小写罗马数字、大写罗马数字、大写字母编号 或 小写字母编号。</li>
</ul>
<h1 id="个人常用命令"><a href="#个人常用命令" class="headerlink" title="个人常用命令"></a>个人常用命令</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">\newcommand&#123;\tabincell&#125;[2]&#123;\begin&#123;tabular&#125;&#123;@&#123;&#125;#1@&#123;&#125;&#125;#2\end&#123;tabular&#125;&#125;</span><br><span class="line"># 加红</span><br><span class="line">\newcommand&#123;\cx&#125;[1]&#123;\textcolor&#123;black&#125;&#123;#1&#125;&#125;</span><br></pre></td></tr></table></figure>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol>
<li><a href="https://tex.stackexchange.com/questions/20140/can-a-table-include-a-horizontal-dashed-line">Can a table include a horizontal dashed line?</a></li>
<li><a href="https://blog.csdn.net/moonlightpeng/article/details/88138586">latex longtable and supertabular 跨页表格</a></li>
<li><a href="https://blog.csdn.net/haifeng_gu/article/details/109168733">Latex中设置enumerate有序列表使用方括号标号以及设置item间距</a></li>
<li><a href="https://blog.csdn.net/bleedingfight/article/details/80169003">LaTeX入门学习(5)(表格)</a></li>
<li><a href="https://blog.csdn.net/wangliandehanyun/article/details/9471427">LaTex中表格固定列宽并且居中的方法</a></li>
<li><a href="https://www.jianshu.com/p/9d73201b965b">LaTeX固定表格每一列宽度并指定对齐方式（居中）</a></li>
</ol>
]]></content>
      <categories>
        <category>Latex</category>
      </categories>
      <tags>
        <tag>Latex</tag>
      </tags>
  </entry>
  <entry>
    <title>ptyhon数组堆叠</title>
    <url>/archives/bcd3a59.html</url>
    <content><![CDATA[<p>常见的方法有torch.cat,torch.stack,np.cat,np.stack</p>
<a id="more"></a>

<h1 id="torch"><a href="#torch" class="headerlink" title="torch"></a>torch</h1><ol>
<li>torch.cat<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> torch</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>A=torch.ones(<span class="number">2</span>,<span class="number">3</span>) <span class="comment">#2x3的张量（矩阵）</span></span><br><span class="line">tensor([[ <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>],</span><br><span class="line">        [ <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>B=<span class="number">2</span>*torch.ones(<span class="number">4</span>,<span class="number">3</span>)<span class="comment">#4x3的张量（矩阵）  </span></span><br><span class="line">tensor([[ <span class="number">2.</span>,  <span class="number">2.</span>,  <span class="number">2.</span>],</span><br><span class="line">        [ <span class="number">2.</span>,  <span class="number">2.</span>,  <span class="number">2.</span>],</span><br><span class="line">        [ <span class="number">2.</span>,  <span class="number">2.</span>,  <span class="number">2.</span>],</span><br><span class="line">        [ <span class="number">2.</span>,  <span class="number">2.</span>,  <span class="number">2.</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span> C=torch.cat((A,B)) <span class="comment"># or C=torch.cat((A,B),0)</span></span><br><span class="line">tensor([[ <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>],</span><br><span class="line">         [ <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>],</span><br><span class="line">         [ <span class="number">2.</span>,  <span class="number">2.</span>,  <span class="number">2.</span>],</span><br><span class="line">         [ <span class="number">2.</span>,  <span class="number">2.</span>,  <span class="number">2.</span>],</span><br><span class="line">         [ <span class="number">2.</span>,  <span class="number">2.</span>,  <span class="number">2.</span>],</span><br><span class="line">         [ <span class="number">2.</span>,  <span class="number">2.</span>,  <span class="number">2.</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>D=<span class="number">2</span>*torch.ones(<span class="number">2</span>,<span class="number">4</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>C=torch.cat((A,D),<span class="number">1</span>)<span class="comment">#按维数1（列）拼接</span></span><br><span class="line">tensor([[ <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">2.</span>,  <span class="number">2.</span>,  <span class="number">2.</span>,  <span class="number">2.</span>],</span><br><span class="line">        [ <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">2.</span>,  <span class="number">2.</span>,  <span class="number">2.</span>,  <span class="number">2.</span>]])</span><br></pre></td></tr></table></figure></li>
<li>torch.stack<br>函数stack()对序列数据内部的张量进行<strong>扩维</strong>拼接，指定维度由程序员选择、大小是生成后数据的维度区间。<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>A=torch.rand(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>B=torch.ones(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.stack((A,B),dim=<span class="number">0</span>) <span class="comment"># shape: [2, 3, 3]</span></span><br><span class="line">tensor([[[<span class="number">0.7021</span>, <span class="number">0.8243</span>, <span class="number">0.5045</span>],</span><br><span class="line">         [<span class="number">0.8906</span>, <span class="number">0.0391</span>, <span class="number">0.1455</span>],</span><br><span class="line">         [<span class="number">0.1793</span>, <span class="number">0.5437</span>, <span class="number">0.2779</span>]],</span><br><span class="line">        [[<span class="number">0.8316</span>, <span class="number">0.1665</span>, <span class="number">0.1453</span>],</span><br><span class="line">         [<span class="number">0.1797</span>, <span class="number">0.8958</span>, <span class="number">0.8249</span>],</span><br><span class="line">         [<span class="number">0.3707</span>, <span class="number">0.0720</span>, <span class="number">0.9599</span>]]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.stack((A,B),dim=<span class="number">1</span>) <span class="comment"># shape: [3, 2, 3]</span></span><br><span class="line">tensor([[[<span class="number">0.7021</span>, <span class="number">0.8243</span>, <span class="number">0.5045</span>],</span><br><span class="line">         [<span class="number">0.8316</span>, <span class="number">0.1665</span>, <span class="number">0.1453</span>]],</span><br><span class="line">        [[<span class="number">0.8906</span>, <span class="number">0.0391</span>, <span class="number">0.1455</span>],</span><br><span class="line">         [<span class="number">0.1797</span>, <span class="number">0.8958</span>, <span class="number">0.8249</span>]],</span><br><span class="line">        [[<span class="number">0.1793</span>, <span class="number">0.5437</span>, <span class="number">0.2779</span>],</span><br><span class="line">         [<span class="number">0.3707</span>, <span class="number">0.0720</span>, <span class="number">0.9599</span>]]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.stack((A,B),dim=<span class="number">2</span>) <span class="comment"># shape: [3, 3, 2]</span></span><br><span class="line">tensor([[[<span class="number">0.7021</span>, <span class="number">0.8316</span>],</span><br><span class="line">         [<span class="number">0.8243</span>, <span class="number">0.1665</span>],</span><br><span class="line">         [<span class="number">0.5045</span>, <span class="number">0.1453</span>]],</span><br><span class="line">        [[<span class="number">0.8906</span>, <span class="number">0.1797</span>],</span><br><span class="line">         [<span class="number">0.0391</span>, <span class="number">0.8958</span>],</span><br><span class="line">         [<span class="number">0.1455</span>, <span class="number">0.8249</span>]],</span><br><span class="line">        [[<span class="number">0.1793</span>, <span class="number">0.3707</span>],</span><br><span class="line">         [<span class="number">0.5437</span>, <span class="number">0.0720</span>],</span><br><span class="line">         [<span class="number">0.2779</span>, <span class="number">0.9599</span>]]])</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="numpy"><a href="#numpy" class="headerlink" title="numpy"></a>numpy</h1>Python中numpy数组的合并有很多方法，如<br>np.append()<br>np.concatenate()<br>np.stack()<br>np.hstack()<br>np.vstack()<br>np.dstack()<br>其中最泛用的是第一个和第二个。第一个可读性好，比较灵活，但是占内存大。第二个则没有内存占用大的问题。</li>
</ol>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol>
<li><a href="https://blog.csdn.net/qq_39516859/article/details/80666070">Python中numpy数组的拼接、合并</a></li>
</ol>
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>数组堆叠</tag>
      </tags>
  </entry>
  <entry>
    <title>ptyhon数组堆叠</title>
    <url>/archives/bcd3a59.html</url>
    <content><![CDATA[<p>常见的方法有torch.cat,torch.stack,np.cat,np.stack</p>
<a id="more"></a>

<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol>
<li><a href="https://blog.csdn.net/qq_39516859/article/details/80666070">Python中numpy数组的拼接、合并</a></li>
</ol>
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>数组堆叠</tag>
      </tags>
  </entry>
  <entry>
    <title>pytorch入门学习</title>
    <url>/archives/8c4d4d4a.html</url>
    <content><![CDATA[<h1 id="Tensors"><a href="#Tensors" class="headerlink" title="Tensors"></a>Tensors</h1><ul>
<li>从数据中生成<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data = [[<span class="number">1</span>, <span class="number">2</span>],[<span class="number">3</span>, <span class="number">4</span>]]</span><br><span class="line">x_data = torch.tensor(data)</span><br></pre></td></tr></table></figure></li>
<li>从numpy数组中生成<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">np_array = np.array(data)</span><br><span class="line">x_np = torch.from_numpy(np_array)</span><br></pre></td></tr></table></figure></li>
<li>从其他tensor中生成<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x_ones = torch.ones_like(x_data) <span class="comment"># retains the properties of x_data</span></span><br><span class="line">x_rand = torch.rand_like(x_data, dtype=torch.<span class="built_in">float</span>) <span class="comment"># overrides the datatype of x_data</span></span><br></pre></td></tr></table></figure>
<h2 id="Tensor的属性"><a href="#Tensor的属性" class="headerlink" title="Tensor的属性"></a>Tensor的属性</h2>Tensor的属性包括shape，datatype和device<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tensor = torch.rand(<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">print(<span class="string">f&quot;Shape of tensor: <span class="subst">&#123;tensor.shape&#125;</span>&quot;</span>)</span><br><span class="line">print(<span class="string">f&quot;Datatype of tensor: <span class="subst">&#123;tensor.dtype&#125;</span>&quot;</span>)</span><br><span class="line">print(<span class="string">f&quot;Device tensor is stored on: <span class="subst">&#123;tensor.device&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="tensor转numpy"><a href="#tensor转numpy" class="headerlink" title="tensor转numpy"></a>tensor转numpy</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">y = x.numpy()</span><br><span class="line">x_np = x.data.cpu().numpy() <span class="comment"># cuda转numpy</span></span><br></pre></td></tr></table></figure></li>
</ul>
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>使用NLTK进行文本处理</title>
    <url>/archives/42874102.html</url>
    <content><![CDATA[<h1 id="NLTK"><a href="#NLTK" class="headerlink" title="NLTK"></a>NLTK</h1><p>NLTK是Python很强大的第三方库，可以很方便的完成很多自然语言处理（NLP）的任务，包括分词、词性标注、命名实体识别（NER）及句法分析。</p>
<h2 id="NLTK进行分词"><a href="#NLTK进行分词" class="headerlink" title="NLTK进行分词"></a>NLTK进行分词</h2><p>使用的函数：</p>
<p>nltk.sent_tokenize(text) #对文本按照句子进行分割</p>
<p>nltk.word_tokenize(sent) #对句子进行分词</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> nltk</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>text = <span class="string">&quot;cslzhl.github.io is a very good blog. We can learn a lot from it.&quot;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># 将文本拆分成句子列表，根据. ?等符号划分，逗号无效</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>sen = nltk.sent_tokenize(text) </span><br><span class="line">[<span class="string">&#x27;cslzhl.github.io is a very good blog.&#x27;</span>, <span class="string">&#x27;We can learn a lot from it.&#x27;</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>words = [nltk.word_tokenize(sent) <span class="keyword">for</span> sent <span class="keyword">in</span> sen]</span><br><span class="line">[[<span class="string">&#x27;cslzhl.github.io&#x27;</span>, <span class="string">&#x27;is&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;very&#x27;</span>, <span class="string">&#x27;good&#x27;</span>, <span class="string">&#x27;blog&#x27;</span>, <span class="string">&#x27;.&#x27;</span>], [<span class="string">&#x27;We&#x27;</span>, <span class="string">&#x27;can&#x27;</span>, <span class="string">&#x27;learn&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;lot&#x27;</span>, <span class="string">&#x27;from&#x27;</span>, <span class="string">&#x27;it&#x27;</span>, <span class="string">&#x27;.&#x27;</span>]]</span><br></pre></td></tr></table></figure>
<p>使用</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> nltk.tokenize <span class="keyword">import</span> WordPunctTokenizer</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>s = <span class="string">&quot;Good muffins cost $3.88\nin New York.  Please buy me\ntwo of them.\n\nThanks.&quot;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>WordPunctTokenizer().tokenize(s) <span class="comment"># 字母和非字母分开</span></span><br><span class="line">[<span class="string">&#x27;Good&#x27;</span>, <span class="string">&#x27;muffins&#x27;</span>, <span class="string">&#x27;cost&#x27;</span>, <span class="string">&#x27;$&#x27;</span>, <span class="string">&#x27;3&#x27;</span>, <span class="string">&#x27;.&#x27;</span>, <span class="string">&#x27;88&#x27;</span>, <span class="string">&#x27;in&#x27;</span>, <span class="string">&#x27;New&#x27;</span>, <span class="string">&#x27;York&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;.&#x27;</span>, <span class="string">&#x27;Please&#x27;</span>, <span class="string">&#x27;buy&#x27;</span>, <span class="string">&#x27;me&#x27;</span>, <span class="string">&#x27;two&#x27;</span>, <span class="string">&#x27;of&#x27;</span>, <span class="string">&#x27;them&#x27;</span>, <span class="string">&#x27;.&#x27;</span>, <span class="string">&#x27;Thanks&#x27;</span>, <span class="string">&#x27;.&#x27;</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>nltk.word_tokenize(s)</span><br><span class="line">[<span class="string">&#x27;Good&#x27;</span>, <span class="string">&#x27;muffins&#x27;</span>, <span class="string">&#x27;cost&#x27;</span>, <span class="string">&#x27;$&#x27;</span>, <span class="string">&#x27;3.88&#x27;</span>, <span class="string">&#x27;in&#x27;</span>, <span class="string">&#x27;New&#x27;</span>, <span class="string">&#x27;York&#x27;</span>, <span class="string">&#x27;.&#x27;</span>, <span class="string">&#x27;Please&#x27;</span>, <span class="string">&#x27;buy&#x27;</span>, <span class="string">&#x27;me&#x27;</span>, <span class="string">&#x27;two&#x27;</span>, <span class="string">&#x27;of&#x27;</span>, <span class="string">&#x27;them&#x27;</span>, <span class="string">&#x27;.&#x27;</span>, <span class="string">&#x27;Thanks&#x27;</span>, <span class="string">&#x27;.&#x27;</span>]</span><br></pre></td></tr></table></figure>
<h2 id="NLTK进行词性标注"><a href="#NLTK进行词性标注" class="headerlink" title="NLTK进行词性标注"></a>NLTK进行词性标注</h2><p>用到的函数：<br>nltk.pos_tag(tokens)#tokens是句子分词后的结果，同样是句子级的标注</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>tags = [nltk.pos_tag(tokens) <span class="keyword">for</span> tokens <span class="keyword">in</span> words] </span><br><span class="line">[[(<span class="string">&#x27;cslzhl.github.io&#x27;</span>, <span class="string">&#x27;NN&#x27;</span>), (<span class="string">&#x27;is&#x27;</span>, <span class="string">&#x27;VBZ&#x27;</span>), (<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;DT&#x27;</span>), (<span class="string">&#x27;very&#x27;</span>, <span class="string">&#x27;RB&#x27;</span>), (<span class="string">&#x27;good&#x27;</span>, <span class="string">&#x27;JJ&#x27;</span>), (<span class="string">&#x27;blog&#x27;</span>, <span class="string">&#x27;NN&#x27;</span>), (<span class="string">&#x27;.&#x27;</span>, <span class="string">&#x27;.&#x27;</span>)], [(<span class="string">&#x27;We&#x27;</span>, <span class="string">&#x27;PRP&#x27;</span>), (<span class="string">&#x27;can&#x27;</span>, <span class="string">&#x27;MD&#x27;</span>), (<span class="string">&#x27;learn&#x27;</span>, <span class="string">&#x27;VB&#x27;</span>), (<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;DT&#x27;</span>), (<span class="string">&#x27;lot&#x27;</span>, <span class="string">&#x27;NN&#x27;</span>), (<span class="string">&#x27;from&#x27;</span>, <span class="string">&#x27;IN&#x27;</span>), (<span class="string">&#x27;it&#x27;</span>, <span class="string">&#x27;PRP&#x27;</span>), (<span class="string">&#x27;.&#x27;</span>, <span class="string">&#x27;.&#x27;</span>)]]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># NN 名词，VB动词（原形），VBZ，动词（第三人称单数），DT限定词等等</span></span><br></pre></td></tr></table></figure>
<h2 id="NLTK词干提取（stemming）"><a href="#NLTK词干提取（stemming）" class="headerlink" title="NLTK词干提取（stemming）"></a>NLTK词干提取（stemming）</h2><p>Stemming 是抽取词的词干或词根形式（不一定能够表达完整语义）。NLTK中提供了三种最常用的词干提取器接口，即 Porter stemmer, Lancaster Stemmer 和 Snowball Stemmer。</p>
<ul>
<li>Porter Stemmer基于Porter词干提取算法，来看例子： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> nltk.stem.porter <span class="keyword">import</span> PorterStemmer  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>porter_stemmer = PorterStemmer()  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>porter_stemmer.stem(‘maximum’)  </span><br><span class="line">u’maximum’  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>porter_stemmer.stem(‘presumably’)  </span><br><span class="line">u’presum’  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>porter_stemmer.stem(‘multiply’)  </span><br><span class="line">u’multipli’  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>porter_stemmer.stem(‘provision’)  </span><br><span class="line">u’provis’  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>porter_stemmer.stem(‘owed’)  </span><br><span class="line">u’owe’  </span><br></pre></td></tr></table></figure></li>
<li>ancaster Stemmer 基于Lancaster 词干提取算法，来看例子<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> nltk.stem.lancaster <span class="keyword">import</span> LancasterStemmer  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lancaster_stemmer = LancasterStemmer()  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lancaster_stemmer.stem(‘maximum’)  </span><br><span class="line">‘maxim’  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lancaster_stemmer.stem(‘presumably’)  </span><br><span class="line">‘presum’  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lancaster_stemmer.stem(‘presumably’)  </span><br><span class="line">‘presum’  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lancaster_stemmer.stem(‘multiply’)  </span><br><span class="line">‘multiply’  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lancaster_stemmer.stem(‘provision’)  </span><br><span class="line">u’provid’  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lancaster_stemmer.stem(‘owed’)  </span><br><span class="line">‘ow’  </span><br></pre></td></tr></table></figure></li>
<li>Snowball Stemmer基于Snowball 词干提取算法，来看例子<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> nltk.stem <span class="keyword">import</span> SnowballStemmer  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>snowball_stemmer = SnowballStemmer(“english”)  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>snowball_stemmer.stem(‘maximum’)  </span><br><span class="line">u’maximum’  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>snowball_stemmer.stem(‘presumably’)  </span><br><span class="line">u’presum’  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>snowball_stemmer.stem(‘multiply’)  </span><br><span class="line">u’multipli’  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>snowball_stemmer.stem(‘provision’)  </span><br><span class="line">u’provis’  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>snowball_stemmer.stem(‘owed’)  </span><br><span class="line">u’owe’  </span><br></pre></td></tr></table></figure>
<blockquote>
<p>词形还原（lemmatization）<br>Lemmatisation是把一个任何形式的语言词汇还原为一般形式（能表达完整语义）。相对而言，词干提取是简单的轻量级的词形归并方式，最后获得的结果为词干，并不一定具有实际意义。词形还原处理相对复杂，获得结果为词的原形，能够承载一定意义，与词干提取相比，更具有研究和应用价值。</p>
</blockquote>
</li>
</ul>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol>
<li><a href="https://blog.csdn.net/a18852867035/article/details/54134281/">python自然语言处理（一）NLTK初步使用</a></li>
</ol>
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>文本处理</tag>
        <tag>NLTK</tag>
      </tags>
  </entry>
  <entry>
    <title>使用gensim进行文本处理</title>
    <url>/archives/ff4fc7ce.html</url>
    <content><![CDATA[]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>文本处理</tag>
        <tag>genssim</tag>
      </tags>
  </entry>
  <entry>
    <title>使用spacy进行文本处理</title>
    <url>/archives/e58dc34c.html</url>
    <content><![CDATA[<p>工业级Python自然语言处理软件包Spacy。Spacy 是由 cython 编写。因此它是一个非常快的库。 spaCy 提供简洁的接口用来访问其方法和属性（ governed by trained machine (and deep) learning models）</p>
<a id="more"></a>

<h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><p>安装Spacy</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pip install spacy</span><br></pre></td></tr></table></figure>
<p>下载数据和模型</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">python -m spacy download en</span><br></pre></td></tr></table></figure>
<p>补充：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 使用conda安装，参考https://anaconda.org/conda-forge/spacy-model-en_vectors_web_lg</span></span><br><span class="line">conda install -c conda-forge spacy-model-en_vectors_web_lg</span><br><span class="line">conda install -c conda-forge/label/cf202003 spacy-model-en_vectors_web_lg</span><br></pre></td></tr></table></figure>
<h1 id="Spacy-流水线-和-属性"><a href="#Spacy-流水线-和-属性" class="headerlink" title="Spacy 流水线 和 属性"></a>Spacy 流水线 和 属性</h1><p>要想使用 Spacy 和 访问其不同的 properties， 需要先创建 pipelines。 通过加载 模型 来创建一个 pipeline。 Spacy 提供了许多不同的 模型 , 模型中包含了 语言的信息- 词汇表，预训练的词向量，语法 和 实体。</p>
<p>下面将加载默认的模型- english-core-web</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> spacy </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>nlp = spacy.load(“en”)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>text = <span class="string">&quot;The sequel, Yes, Prime Minister, ran from 1986 to 1988. In total there were 38 episodes, of which all but one lasted half an hour. Almost all episodes ended with a variation of the title of the series spoken as the answer to a question posed by the same character, Jim Hacker. Several episodes were adapted for BBC Radio, and a stage play was produced in 2010, the latter leading to a new television series on UKTV Gold in 2013.&quot;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>doc = nlp(text)</span><br><span class="line"><span class="string">&quot;The&quot;</span></span><br><span class="line"><span class="string">&quot;sequel&quot;</span></span><br><span class="line"><span class="string">&quot;,&quot;</span></span><br><span class="line"><span class="string">&quot;Yes&quot;</span>...</span><br></pre></td></tr></table></figure>
<p>document 也有一些 成员属性。可以通过 $dir(doc)$ 查看</p>
<p>下面，我们只对前10个词例（token），输出以下内容：<br>文本、索引值（即在原文中的定位）、词元(lemma)、是否为标点符号、是否为空格、词性、标记</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> token <span class="keyword">in</span> doc[:<span class="number">10</span>]:</span><br><span class="line">    print(<span class="string">&quot;&#123;0&#125;\t&#123;1&#125;\t&#123;2&#125;\t&#123;3&#125;\t&#123;4&#125;\t&#123;5&#125;\t&#123;6&#125;\t&#123;7&#125;&quot;</span>.<span class="built_in">format</span>(</span><br><span class="line">        token.text,</span><br><span class="line">        token.idx,</span><br><span class="line">        token.lemma_,</span><br><span class="line">        token.is_punct,</span><br><span class="line">        token.is_space,</span><br><span class="line">        token.shape_,</span><br><span class="line">        token.pos_,</span><br><span class="line">        token.tag_</span><br><span class="line">    ))</span><br></pre></td></tr></table></figure>
<p>结果为</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">The 0   the False   False   Xxx DET DT</span><br><span class="line">sequel  4   sequel  False   False   xxxx    NOUN    NN</span><br><span class="line">,   10  ,   True    False   ,   PUNCT   ,</span><br><span class="line">Yes 12  yes False   False   Xxx INTJ    UH</span><br><span class="line">,   15  ,   True    False   ,   PUNCT   ,</span><br><span class="line">Prime   17  prime   False   False   Xxxxx   PROPN   NNP</span><br><span class="line">Minister    23  minister    False   False   Xxxxx   PROPN   NNP</span><br><span class="line">,   31  ,   True    False   ,   PUNCT   ,</span><br><span class="line">ran 33  run False   False   xxx VERB    VBD</span><br><span class="line">from    37  from    False   False   xxxx    ADP IN</span><br></pre></td></tr></table></figure>
<h2 id="词性标注"><a href="#词性标注" class="headerlink" title="词性标注"></a>词性标注</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>all_tags = &#123;w.pos: w.pos_ <span class="keyword">for</span> w <span class="keyword">in</span> doc&#125;</span><br><span class="line">&#123;<span class="number">90</span>: <span class="string">&#x27;DET&#x27;</span>,<span class="number">92</span>: <span class="string">&#x27;NOUN&#x27;</span>,<span class="number">97</span>: <span class="string">&#x27;PUNCT&#x27;</span>,<span class="number">91</span>: <span class="string">&#x27;INTJ&#x27;</span>,<span class="number">96</span>: <span class="string">&#x27;PROPN&#x27;</span>,<span class="number">100</span>: <span class="string">&#x27;VERB&#x27;</span>,<span class="number">85</span>: <span class="string">&#x27;ADP&#x27;</span>,<span class="number">93</span>: <span class="string">&#x27;NUM&#x27;</span>,<span class="number">95</span>: <span class="string">&#x27;PRON&#x27;</span>,<span class="number">87</span>: <span class="string">&#x27;AUX&#x27;</span>,<span class="number">98</span>: <span class="string">&#x27;SCONJ&#x27;</span>,<span class="number">86</span>: <span class="string">&#x27;ADV&#x27;</span>,<span class="number">84</span>: <span class="string">&#x27;ADJ&#x27;</span>,<span class="number">89</span>: <span class="string">&#x27;CCONJ&#x27;</span>&#125;</span><br></pre></td></tr></table></figure>
<h2 id="实体检测"><a href="#实体检测" class="headerlink" title="实体检测"></a>实体检测</h2><p>Spacy 包含了一个快速的 实体识别模型，它可以识别出文档中的 实体短语。有多种类型的实体，例如 - 人物，地点，组织，日期，数字。可以通过 document 的 ents 属性来访问这些实体。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> ent <span class="keyword">in</span> doc.ents:</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>    print(ent.text, ent.label_)</span><br></pre></td></tr></table></figure>
<h2 id="语句划分"><a href="#语句划分" class="headerlink" title="语句划分"></a>语句划分</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> sent <span class="keyword">in</span> doc.sents:</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>    print(sent)</span><br></pre></td></tr></table></figure>
<h2 id="词嵌入"><a href="#词嵌入" class="headerlink" title="词嵌入"></a>词嵌入</h2><p>使用词嵌入模型，我们需要Spacy读取一个新的文件。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>nlp = spacy.load(<span class="string">&#x27;en_core_web_lg&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(nlp.vocab[<span class="string">&#x27;minister&#x27;</span>].vector) <span class="comment"># 读取单词对应的词向量</span></span><br></pre></td></tr></table></figure>
<p>词语义的近似度计算</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>dog = nlp.vocab[<span class="string">&quot;dog&quot;</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>cat = nlp.vocab[<span class="string">&quot;cat&quot;</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dog.similarity(cat)</span><br><span class="line"><span class="number">0.80168545</span></span><br></pre></td></tr></table></figure>
<p>计算词典中可能不存在的向量，因此Spacy自带的similarity()函数，就显得不够用了。我们从scipy中，找到相似度计算需要用到的余弦函数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> scipy.spatial.distance <span class="keyword">import</span> cosine</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">1</span> - cosine(dog.vector, cat.vector) <span class="comment"># 与上述结果相同</span></span><br><span class="line"><span class="number">0.8016855120658875</span></span><br></pre></td></tr></table></figure>



<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol>
<li><a href="https://blog.csdn.net/u012436149/article/details/79321112">使用 spacy 进行自然语言处理（一）</a></li>
<li><a href="https://www.jianshu.com/p/1ede048ef7e6">如何用Python处理自然语言？（Spacy与Word Embedding）</a></li>
</ol>
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>文本处理</tag>
        <tag>spacy</tag>
      </tags>
  </entry>
  <entry>
    <title>学习排序算法</title>
    <url>/archives/4f2a5e3e.html</url>
    <content><![CDATA[]]></content>
  </entry>
</search>
